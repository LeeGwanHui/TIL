{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SEHO-jaFj9Zm"
   },
   "source": [
    "> ### EEE4423: Deep Learning Lab\n",
    "\n",
    "# LAB \\#3: CNN: VGG Net and ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HVdm1LA1j9Zo"
   },
   "source": [
    "<h4><div style=\"text-align: right\"> Due date: March 25, 2022.  </div> <br>\n",
    "<div style=\"text-align: right\"> Please upload your file @ LearnUs by 9 AM in the form of [ID_Name_Lab03.ipynb]. </div></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8cl2DqlTj9Zp"
   },
   "source": [
    "### *Instructions:*\n",
    "- Write a program implementing a particular algorithm to solve a given problem.   \n",
    "- <span style=\"color:red\">**Report and discuss your results. Analyze the algorithm, theoretically and empirically.**</span> \n",
    "- Each team must write their own answers and codes (<span style=\"color:red\">**if not you will get a F grade**</span>)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKipoMbMj9Zq"
   },
   "source": [
    "<h2><span style=\"color:blue\">[Insert your ID HERE] [Insert your name HERE]</span> </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-02-25T09:44:49.874164Z",
     "iopub.status.busy": "2022-02-25T09:44:49.873644Z",
     "iopub.status.idle": "2022-02-25T09:44:49.973560Z",
     "shell.execute_reply": "2022-02-25T09:44:49.972227Z",
     "shell.execute_reply.started": "2022-02-25T09:44:49.874109Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1647947001660,
     "user": {
      "displayName": "Lee gwan hui",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09079206913426271362"
     },
     "user_tz": -540
    },
    "id": "VL1pbTi2j9Zr",
    "outputId": "5c0b3b99-3b24-4660-f6d2-0e5db5220181"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This code is written at 2022-03-22 11:03:21.127117\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(\"This code is written at \" + str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VpPLjwr8j9Zw"
   },
   "source": [
    "## 1. VGGNet with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IWeEYLiSj9Zx"
   },
   "source": [
    "### Implementing VGGNet\n",
    "\n",
    "> 1. **Dataset**\n",
    ">> - Images from the first three categories in CIFAR-10. (Due to the computational constraints.)  <br>\n",
    "     Three categories : plane, car, bird  /  The number of training images : 15,000   /  The number of test images : 3,000\n",
    ">> - Augmented with flipping and random cropping.\n",
    ">\n",
    "> 2. **Network architecture**\n",
    ">> - Type-D configuration in the paper (+ 3-way classifier after convolutional layers).\n",
    ">> - ReLU activation.\n",
    ">> - No dropout for simplicity.\n",
    ">> - We will apply **batch-normalization** after every convolution which is not used in the paper (otherwise, hard to optimize).\n",
    ">>\n",
    ">> <table><tr>\n",
    ">> <td> <img src=\"http://drive.google.com/uc?export=view&id=1jn7ICUJAcTF3WQ1XuUffOdmprgj4u1c3\" alt=\"no_image\" style=\"width: 550px;\"/> </td>\n",
    ">> <td> <img src=\"http://drive.google.com/uc?export=view&id=1Rz0iWW6VoLD_XGdRa3ofYyhCTTb6kR_k\" alt=\"no_image\" style=\"width: 250px;\"/> </td>\n",
    ">> </tr></table>\n",
    ">>\n",
    ">> <font size=\"0.5\"> Figure from <br>\n",
    ">> [1] https://www.quora.com/What-is-the-VGG-neural-network </font>\n",
    ">\n",
    "> 3. **Loss function**\n",
    ">> - Cross-entropy loss between outputs & ground-truths. <br>\n",
    "     Note that `nn.CrossEntroyLoss` takes logits before softmax as network outputs and scalar index (not one-hot vector) as ground-truths.<br>\n",
    "     See https://pytorch.org/docs/stable/nn.html#crossentropyloss for details.\n",
    ">\n",
    "> 4. **Training**\n",
    ">> - Default weight initialization for simplicity.\n",
    ">> - SGD optimizer with `learning rate = 1e-2`, `momentum = 0.9`, and `weight_decay = 5e-4`.\n",
    ">> - 20 epochs without learning rate scheduling.\n",
    ">\n",
    "> 5. **Evaluation metric**\n",
    ">> - Classification accuracy (i.e., the percentage of correct predictions).\n",
    ">\n",
    "> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T09:44:50.978522Z",
     "iopub.status.busy": "2022-02-25T09:44:50.978032Z",
     "iopub.status.idle": "2022-02-25T09:45:04.679815Z",
     "shell.execute_reply": "2022-02-25T09:45:04.678372Z",
     "shell.execute_reply.started": "2022-02-25T09:44:50.978472Z"
    },
    "executionInfo": {
     "elapsed": 6333,
     "status": "ok",
     "timestamp": 1647947032629,
     "user": {
      "displayName": "Lee gwan hui",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09079206913426271362"
     },
     "user_tz": -540
    },
    "id": "LGgir5u7j9Zy"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets \n",
    "import torchvision\n",
    "import time\n",
    "import os\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "execution": {
     "iopub.execute_input": "2022-02-25T09:45:04.774519Z",
     "iopub.status.busy": "2022-02-25T09:45:04.774143Z",
     "iopub.status.idle": "2022-02-25T09:46:38.276105Z",
     "shell.execute_reply": "2022-02-25T09:46:38.274252Z",
     "shell.execute_reply.started": "2022-02-25T09:45:04.774475Z"
    },
    "executionInfo": {
     "elapsed": 46373,
     "status": "ok",
     "timestamp": 1549956503374,
     "user": {
      "displayName": "­이중협(대학원/일반대학원 전기전자공학과)",
      "photoUrl": "",
      "userId": "06027175232332113122"
     },
     "user_tz": -540
    },
    "id": "OwvpXFuaj9Z0",
    "outputId": "0943c291-534d-4930-e426-a650e204cdba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: LOADING DATASET\n",
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../dataset/lab03\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1.8%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "6.7%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "11.8%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "18.4%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "24.0%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "28.9%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "35.0%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "41.9%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "49.4%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "57.4%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "64.8%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "71.0%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "78.7%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "85.6%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "91.8%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "99.7%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('STEP 1: LOADING DATASET')\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "train_dataset = dsets.CIFAR10(root='../dataset/lab03', \n",
    "                            train=True, \n",
    "                            transform=transform_train,\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.CIFAR10(root='../dataset/lab03', \n",
    "                           train=False, \n",
    "                           transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T09:46:38.574773Z",
     "iopub.status.busy": "2022-02-25T09:46:38.574244Z",
     "iopub.status.idle": "2022-02-25T09:51:22.080888Z",
     "shell.execute_reply": "2022-02-25T09:51:22.079134Z",
     "shell.execute_reply.started": "2022-02-25T09:46:38.574727Z"
    },
    "id": "DrK0ZHmLj9Z4"
   },
   "outputs": [],
   "source": [
    "# reducing the dataset\n",
    "reduced_train_dataset = []\n",
    "for images, labels in train_dataset:\n",
    "    if labels < 3:\n",
    "        reduced_train_dataset.append((images, labels))\n",
    "        \n",
    "reduced_test_dataset = []\n",
    "for images, labels in test_dataset:\n",
    "    if labels < 3:\n",
    "        reduced_test_dataset.append((images, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "executionInfo": {
     "elapsed": 63102,
     "status": "ok",
     "timestamp": 1549956520111,
     "user": {
      "displayName": "­이중협(대학원/일반대학원 전기전자공학과)",
      "photoUrl": "",
      "userId": "06027175232332113122"
     },
     "user_tz": -540
    },
    "id": "LWnYJ2cwj9Z6",
    "outputId": "eadaf55c-432b-4956-d36e-2e1064f10a62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of training images :  15000\n",
      "The number of test images :  3000\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of training images : \", len(reduced_train_dataset))\n",
    "print(\"The number of test images : \", len(reduced_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 63097,
     "status": "ok",
     "timestamp": 1549956520112,
     "user": {
      "displayName": "­이중협(대학원/일반대학원 전기전자공학과)",
      "photoUrl": "",
      "userId": "06027175232332113122"
     },
     "user_tz": -540
    },
    "id": "WFq0isyCj9Z-",
    "outputId": "0a486f6b-d1b2-4475-c20b-83fe0ac90fa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 2: MAKING DATASET ITERABLE\n"
     ]
    }
   ],
   "source": [
    "print('STEP 2: MAKING DATASET ITERABLE')\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=reduced_train_dataset, \n",
    "                                           batch_size=128, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=reduced_test_dataset, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=False)\n",
    "\n",
    "class_names = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wy7GW1lkj9aB"
   },
   "source": [
    "### Visualize a few images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tJGv35Alj9aC"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3PYou4Cuj9aE"
   },
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.4914, 0.4822, 0.4465])\n",
    "    std = np.array([0.2023, 0.1994, 0.2010])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 150
    },
    "executionInfo": {
     "elapsed": 63086,
     "status": "ok",
     "timestamp": 1549956520118,
     "user": {
      "displayName": "­이중협(대학원/일반대학원 전기전자공학과)",
      "photoUrl": "",
      "userId": "06027175232332113122"
     },
     "user_tz": -540
    },
    "id": "jX59AE2pj9aH",
    "outputId": "795d995f-84c7-4cde-9524-95a3e78ccc6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 2, 2, 0])\n",
      "torch.Size([4, 3, 32, 32])\n",
      "torch.Size([4, 3])\n",
      "tensor([ 5.1776, -3.4805, -1.8904], device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loader_sample = torch.utils.data.DataLoader(dataset=reduced_train_dataset, \n",
    "                                           batch_size=4, \n",
    "                                           shuffle=True)\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(train_loader_sample))\n",
    "# iter과 next 학습\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "print(classes)\n",
    "print(inputs.size())\n",
    "outputs = model(inputs.to(device))\n",
    "print(outputs.size())\n",
    "print(outputs[0,:])\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hzbc_fTrj9aM"
   },
   "source": [
    "### 1.1 Write code (VGG 16) [3 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 63079,
     "status": "ok",
     "timestamp": 1549956520118,
     "user": {
      "displayName": "­이중협(대학원/일반대학원 전기전자공학과)",
      "photoUrl": "",
      "userId": "06027175232332113122"
     },
     "user_tz": -540
    },
    "id": "gjeNHb89j9aN",
    "outputId": "06f21fc1-d7d7-427a-d45d-f3118f915914"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 3: CREATE MODEL CLASS (VGG16)\n"
     ]
    }
   ],
   "source": [
    "print('STEP 3: CREATE MODEL CLASS (VGG16)')\n",
    "\n",
    "class VGG(nn.Module) : \n",
    "    def __init__(self) :\n",
    "        super(VGG,self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "        # 3 32 32\n",
    "        # Convolution 1,2 -> conv3-64 , Max pool\n",
    "        # BatchNorm에 bias가 포함되어 있으므로, conv2d는 bias=False로 설정\n",
    "        nn.Conv2d(in_channels=3, out_channels = 64, kernel_size=3, padding=1,bias=False),nn.BatchNorm2d(64),nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=64, out_channels = 64, kernel_size= 3, padding=1,bias=False),nn.BatchNorm2d(64),nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                    \n",
    "        # 64 16 16\n",
    "        # Convolution 3,4 -> conv3-128 , Max pool\n",
    "        nn.Conv2d(in_channels=64, out_channels = 128, kernel_size=3, padding=1,bias=False),nn.BatchNorm2d(128), nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=128, out_channels = 128, kernel_size= 3, padding=1,bias=False),nn.BatchNorm2d(128), nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        \n",
    "        #128 8 8\n",
    "        # Convolution 5,6,7 -> conv3-256, Max pool\n",
    "        nn.Conv2d(in_channels=128, out_channels = 256, kernel_size=3, padding=1,bias=False),nn.BatchNorm2d(256), nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=256, out_channels = 256, kernel_size= 3, padding=1,bias=False),nn.BatchNorm2d(256), nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=256, out_channels = 256, kernel_size= 3, padding=1,bias=False),nn.BatchNorm2d(256), nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "        # 256 4 4 \n",
    "        # Convolution 8,9,10 -> conv3-512, Max pool\n",
    "        nn.Conv2d(in_channels=256, out_channels = 512, kernel_size=3, padding=1,bias=False),nn.BatchNorm2d(512), nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=512, out_channels = 512, kernel_size= 3, padding=1,bias=False),nn.BatchNorm2d(512), nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=512, out_channels = 512, kernel_size= 3, padding=1,bias=False),nn.BatchNorm2d(512), nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        \n",
    "        # 512 2 2\n",
    "        # Convolution 11,12,13 -> conv3-512, Max pool\n",
    "        nn.Conv2d(in_channels=512, out_channels = 512, kernel_size=3, padding=1,bias=False),nn.BatchNorm2d(512), nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=512, out_channels = 512, kernel_size= 3, padding=1,bias=False),nn.BatchNorm2d(512), nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=512, out_channels = 512, kernel_size= 3, padding=1,bias=False),nn.BatchNorm2d(512), nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),    \n",
    "       #512 1 1\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Linear(in_features=512*1*1, out_features=3) # 마지막이니깐 ReLU()는 필요없다.\n",
    "        \n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.Linear(512 * 1 * 1, 4096),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(4096, 4096),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(4096, 3)\n",
    "#         )\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        x= x.view(x.shape[0],-1) # x.shape[0] =batch size\n",
    "        # shape torch.Size([1, 2, 200, 100]), i.e [batch=1, ch=2, height=200, width=100 ]\n",
    "        #x= x.view(-1,512*1*1)\n",
    "        x= self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 935
    },
    "executionInfo": {
     "elapsed": 68844,
     "status": "ok",
     "timestamp": 1549956525890,
     "user": {
      "displayName": "­이중협(대학원/일반대학원 전기전자공학과)",
      "photoUrl": "",
      "userId": "06027175232332113122"
     },
     "user_tz": -540
    },
    "id": "iqoPZuR3j9aQ",
    "outputId": "6ac6e65f-85f6-4dc2-cd48-a4749bfa9810"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 4: INSTANTIATE MODEL CLASS\n",
      "The number of parameters :  14720451\n",
      "VGG(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU()\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU()\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU()\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU()\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU()\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU()\n",
      "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU()\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU()\n",
      "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (36): ReLU()\n",
      "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (39): ReLU()\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU()\n",
      "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Linear(in_features=512, out_features=3, bias=True)\n",
      ")\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print('STEP 4: INSTANTIATE MODEL CLASS')\n",
    "\n",
    "\n",
    "model = VGG()\n",
    "num_total_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"The number of parameters : \", num_total_params)\n",
    "#######################\n",
    "#  USE GPU FOR MODEL  #\n",
    "#######################\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(model.to(device))\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "executionInfo": {
     "elapsed": 68834,
     "status": "ok",
     "timestamp": 1549956525891,
     "user": {
      "displayName": "­이중협(대학원/일반대학원 전기전자공학과)",
      "photoUrl": "",
      "userId": "06027175232332113122"
     },
     "user_tz": -540
    },
    "id": "mFeamtXXj9aT",
    "outputId": "0cbbaa6a-65ff-4d79-d1e4-2b2580d04039"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 5: INSTANTIATE LOSS CLASS\n",
      "STEP 6: INSTANTIATE OPTIMIZER CLASS\n"
     ]
    }
   ],
   "source": [
    "print('STEP 5: INSTANTIATE LOSS CLASS')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print('STEP 6: INSTANTIATE OPTIMIZER CLASS')\n",
    "\n",
    "learning_rate = 1e-2\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum = momentum, weight_decay = weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TQzesVcBS3Iq",
    "outputId": "534b345e-390c-4fd6-c63e-bbf45428d48d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PaWErvoRj9aY"
   },
   "source": [
    "### 1.2 Train the VGG 16 model and print test accuracy for every epochs [2 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 395
    },
    "executionInfo": {
     "elapsed": 1260714,
     "status": "ok",
     "timestamp": 1549957717778,
     "user": {
      "displayName": "­이중협(대학원/일반대학원 전기전자공학과)",
      "photoUrl": "",
      "userId": "06027175232332113122"
     },
     "user_tz": -540
    },
    "id": "bbi85f2Pj9aY",
    "outputId": "8483debb-2beb-4674-da28-0833c55d0a32",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 7: TRAIN THE MODEL\n",
      "Epochs: 0. Loss: 0.51. Accuracy: 80.60. Elapsed time: 12.86sec\n",
      "Epochs: 1. Loss: 0.33. Accuracy: 85.90. Elapsed time: 4.58sec\n",
      "Epochs: 2. Loss: 0.41. Accuracy: 88.60. Elapsed time: 4.61sec\n",
      "Epochs: 3. Loss: 0.40. Accuracy: 90.30. Elapsed time: 4.58sec\n",
      "Epochs: 4. Loss: 0.08. Accuracy: 91.00. Elapsed time: 4.66sec\n",
      "Epochs: 5. Loss: 0.36. Accuracy: 89.53. Elapsed time: 4.64sec\n",
      "Epochs: 6. Loss: 0.17. Accuracy: 91.43. Elapsed time: 4.66sec\n",
      "Epochs: 7. Loss: 0.04. Accuracy: 92.30. Elapsed time: 4.64sec\n",
      "Epochs: 8. Loss: 0.24. Accuracy: 91.53. Elapsed time: 4.67sec\n",
      "Epochs: 9. Loss: 0.20. Accuracy: 90.20. Elapsed time: 4.62sec\n",
      "Epochs: 10. Loss: 0.03. Accuracy: 92.07. Elapsed time: 4.59sec\n",
      "Epochs: 11. Loss: 0.31. Accuracy: 91.87. Elapsed time: 4.59sec\n",
      "Epochs: 12. Loss: 0.02. Accuracy: 93.20. Elapsed time: 4.65sec\n",
      "Epochs: 13. Loss: 0.06. Accuracy: 91.27. Elapsed time: 4.76sec\n",
      "Epochs: 14. Loss: 0.01. Accuracy: 93.70. Elapsed time: 4.78sec\n",
      "Epochs: 15. Loss: 0.00. Accuracy: 93.33. Elapsed time: 4.62sec\n",
      "Epochs: 16. Loss: 0.02. Accuracy: 93.40. Elapsed time: 4.60sec\n",
      "Epochs: 17. Loss: 0.01. Accuracy: 93.23. Elapsed time: 4.61sec\n",
      "Epochs: 18. Loss: 0.00. Accuracy: 92.97. Elapsed time: 4.61sec\n",
      "Epochs: 19. Loss: 0.01. Accuracy: 93.63. Elapsed time: 4.62sec\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "print('STEP 7: TRAIN THE MODEL')\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs) : \n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        #######################\n",
    "        #  USE GPU FOR MODEL  #\n",
    "        #######################\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images) \n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate Accuracy\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # Iterate through test dataset\n",
    "    for images, labels in test_loader:\n",
    "        #######################\n",
    "        #  USE GPU FOR MODEL  #\n",
    "        #######################\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass only to get logits/output\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Get predictions from the maximum value\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # Total number of labels\n",
    "        total += labels.size(0)\n",
    "\n",
    "        # Total correct predictions\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "    accuracy = 100 * correct.item() / total\n",
    "\n",
    "    end = time.time()\n",
    "    # Print Loss\n",
    "    print('Epochs: {}. Loss: {:.2f}. Accuracy: {:.2f}. Elapsed time: {:.2f}sec'.format(epoch, loss.item(), accuracy, end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sN8yfBmeS3Ir"
   },
   "source": [
    " \"예상했던 점, 예상과 달랐던 점, 또는 개선할 점\"과 같은 요약 내용을 기술해주시면 되겠습니다. (예시) ~ 해서 ~ 결과를 얻었고, 이는 ~ 으로 인한 것으로 생각된다.\"\n",
    " \n",
    " FC layer가 변형된 VGG 16을 디자인해서 대략 93%의 정확도를 가지는 결과를 얻었고 이는  VGG net의 특징인 Convoluational layer depth를 높이면 정확도가 높아진다는 논문의 결과와 일치한다.\n",
    " 예상과 달랐던 점은 전처리 과정이 없이도 90%에 달하는 정확도를 간단한 이미지이지만 RGB 이미지에서 달성했다는 것이다.\n",
    " 좀 더 class가 많고 resolution이 높은 데이터에서 이같은 결과가 생기는지 궁금하고 만약 그렇담 당장 사용할 수 있는 모델이라는 생각이 들었다.\n",
    " \n",
    " \n",
    " 개선할 점 : 학습 데이터에 맞는 전처리 과정이 추가된다면 더 놓은 정확도를 얻을 것이다. epochs 당 실행시간이 길기 때문에 모델의 무게감이 있어 실시간 처리에는 적합하지 않을 것이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tb-Zo5yOj9ac"
   },
   "source": [
    "## 2. ResNet with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQeESvzij9ad"
   },
   "source": [
    "### Implementing ResNet\n",
    "\n",
    "> 1. **Dataset**\n",
    ">> - The same dataset used for VGGNet\n",
    ">\n",
    "> 2. **Network architecture**\n",
    ">> - 50-layer ResNet with **bottleneck blocks**. <br>\n",
    "     Note. The initial convolution layer (i.e., conv1) is different from the one in the paper &<br>\n",
    "     the initial max-pooling layer is removed (because the size of CIFAR-10 images is too small).\n",
    ">> - ReLU activation.\n",
    ">> - Strided convolution for down-sampling instead of max-pooling layer. <br>\n",
    "     Note. Once down-sampled, a $1\\times1$ convolution/stride 2 is applied to residual for expanding the channel of the residual.\n",
    ">> - No dropout for simplicity.\n",
    ">> - Batch-normalization after every convolution.\n",
    ">>\n",
    ">>\n",
    ">> <table><tr>\n",
    ">> <td> <img src=\"http://drive.google.com/uc?export=view&id=1l3rC40WnBXZBagFIuME48SPvcqVY-56Y\" alt=\"no_image\" style=\"width: 500px;\"/> </td>\n",
    ">> <td> <img src=\"http://drive.google.com/uc?export=view&id=1r92UcNqn6ZT5pOk3emEijjTKlWdAYvCk\" alt=\"no_image\" style=\"width: 300px;\"/> </td>\n",
    ">> </tr></table>\n",
    ">>\n",
    ">> <img src=\"http://drive.google.com/uc?export=view&id=1n0NYyWWbDBd9PHjNEs7AHpOhMci5q6qk\" alt=\"no_image\" style=\"width: 870px;\"/>\n",
    ">>\n",
    ">> <font size=\"0.5\"> Figures from <br> \n",
    ">> [1] https://www.codeproject.com/Articles/1248963/Deep-Learning-using-Python-plus-Keras-Chapter-Re  <br> \n",
    ">> [2] Rezende et al., *Signal Processing: Image Communication*, 2018. </font>\n",
    ">\n",
    "> 3. **Loss function**\n",
    ">> - Cross-entropy loss between outputs & ground-truths. <br>\n",
    ">\n",
    "> 4. **Training**\n",
    ">> - Default weight initialization for simplicity.\n",
    ">> - SGD optimizer with `learning rate = 1e-2`, `momentum = 0.9`, and `weight_decay = 5e-4`.\n",
    ">> - 15 epochs without learning rate scheduling.\n",
    ">\n",
    "> 5. **Evaluation metric**\n",
    ">> - Classification accuracy (i.e., the percentage of correct predictions).\n",
    ">\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-guPbqGj9ae"
   },
   "source": [
    "### 2.1 Implement ResNet50 and train it with the CIFAR 10 dataset [4 points] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104,
     "referenced_widgets": [
      "f370d7336a2d4f2b837f2d5facd97dc9",
      "80e94dff268b4b6c8fb1e37675b6b8ed",
      "0d6ea99b60f74a7fa5c72f5b393a5b76",
      "53d4e1d7887040c392bc702803ae4a7e",
      "73b1e9c60bb84e4aa8cd43e284ae333c",
      "a107658c097d44f3a28b8576544ae43a",
      "a3994c9941f74f0a82feca71e676b6ca",
      "c64ded6e30454561a975ac0fe18903a9",
      "3c28cfe5b3994e899bfbe48b89858c60",
      "628b09986c414679bba5afa5470e1fa9",
      "36bdc6607a4f46b1a706665ccc12ea4f"
     ]
    },
    "executionInfo": {
     "elapsed": 10790,
     "status": "ok",
     "timestamp": 1647947053539,
     "user": {
      "displayName": "Lee gwan hui",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09079206913426271362"
     },
     "user_tz": -540
    },
    "id": "k1dZEH_ZS3Ir",
    "outputId": "4a1cb55a-553d-423f-9057-dd97e945d7f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: LOADING DATASET\n",
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../dataset/lab03/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f370d7336a2d4f2b837f2d5facd97dc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../dataset/lab03/cifar-10-python.tar.gz to ../dataset/lab03\n"
     ]
    }
   ],
   "source": [
    "print('STEP 1: LOADING DATASET')\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "train_dataset = dsets.CIFAR10(root='../dataset/lab03', \n",
    "                            train=True, \n",
    "                            transform=transform_train,\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.CIFAR10(root='../dataset/lab03', \n",
    "                           train=False, \n",
    "                           transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 23382,
     "status": "ok",
     "timestamp": 1647947076916,
     "user": {
      "displayName": "Lee gwan hui",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09079206913426271362"
     },
     "user_tz": -540
    },
    "id": "y0LW_E-uS3Ir"
   },
   "outputs": [],
   "source": [
    "# reducing the dataset\n",
    "reduced_train_dataset = []\n",
    "for images, labels in train_dataset:\n",
    "    if labels < 3:\n",
    "        reduced_train_dataset.append((images, labels))\n",
    "        \n",
    "reduced_test_dataset = []\n",
    "for images, labels in test_dataset:\n",
    "    if labels < 3:\n",
    "        reduced_test_dataset.append((images, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1647947076916,
     "user": {
      "displayName": "Lee gwan hui",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09079206913426271362"
     },
     "user_tz": -540
    },
    "id": "6OFpAdmKS3Is",
    "outputId": "43b4afba-556d-4729-9929-1ff3af80e4f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of training images :  15000\n",
      "The number of test images :  3000\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of training images : \", len(reduced_train_dataset))\n",
    "print(\"The number of test images : \", len(reduced_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1647947076917,
     "user": {
      "displayName": "Lee gwan hui",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09079206913426271362"
     },
     "user_tz": -540
    },
    "id": "XVJKnLniS3Is",
    "outputId": "900433b4-2f2c-40c6-cba8-00916a2c27f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 2: MAKING DATASET ITERABLE\n"
     ]
    }
   ],
   "source": [
    "print('STEP 2: MAKING DATASET ITERABLE')\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=reduced_train_dataset, \n",
    "                                           batch_size=128, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=reduced_test_dataset, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=False)\n",
    "\n",
    "class_names = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1647947076917,
     "user": {
      "displayName": "Lee gwan hui",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09079206913426271362"
     },
     "user_tz": -540
    },
    "id": "8wvAZrrQS3Is",
    "outputId": "35232431-0d54-4c95-ef65-0e8197813040"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 3: CREATE MODEL CLASS (ResNet-50)\n"
     ]
    }
   ],
   "source": [
    "print('STEP 3: CREATE MODEL CLASS (ResNet-50)')\n",
    "#############\n",
    "# CODE HERE #\n",
    "#############\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, in_channels,hidden_channels, out_channels, down= False, stride=1):\n",
    "        super().__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        if down == False :\n",
    "            self.bottleneck = nn.Sequential(\n",
    "                ## ex in_channels = 64, hidden_channels=64, out_chaannels =64\n",
    "                ##256x32x32 down이 아닐때: \n",
    "                nn.Conv2d(in_channels, hidden_channels, kernel_size=1, stride=1, bias=False),  ## 여기서 stride는 1이 될 수도 2가 될수도 있다.(down 여부에 따라 결정 혹은 stride 값으로 결정)\n",
    "                nn.BatchNorm2d(hidden_channels), nn.ReLU(),\n",
    "                ## 256x32x32\n",
    "                nn.Conv2d(hidden_channels, hidden_channels, kernel_size=3, stride=1, padding=1, bias=False),  ## 계산\n",
    "                nn.BatchNorm2d(hidden_channels), nn.ReLU(),\n",
    "                ## 256x32x32\n",
    "                nn.Conv2d(hidden_channels, out_channels, kernel_size=1, stride=1, bias=False),  ## 원상 복구\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "                ## 256x32x32\n",
    "            )\n",
    "            self.shortcut = nn.Sequential(\n",
    "            )\n",
    "        elif down == True :\n",
    "            self.bottleneck = nn.Sequential(\n",
    "                ## ex in_channels = 64, hidden_channels=64, out_chaannels =64\n",
    "                ##256x32x32 down일때: \n",
    "                nn.Conv2d(in_channels, hidden_channels, kernel_size=1, stride=stride, bias=False),  ## 여기서 stride는 1이 될 수도 2가 될수도 있다.(down 여부에 따라 결정 혹은 stride 값으로 결정)\n",
    "                nn.BatchNorm2d(hidden_channels), nn.ReLU(),\n",
    "                ## 128x16x16\n",
    "                nn.Conv2d(hidden_channels, hidden_channels, kernel_size=3, stride=1, padding=1, bias=False),  ## 계산\n",
    "                nn.BatchNorm2d(hidden_channels), nn.ReLU(),\n",
    "                ## 128x16x16\n",
    "                nn.Conv2d(hidden_channels, out_channels, kernel_size=1, stride=1, bias=False),  ## 원상 복구\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "                ## 512x16x16\n",
    "            )\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.bottleneck(x) + self.shortcut(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class ResNet_50(nn.Module):\n",
    "    def __init__(self,num_classes: int = 3) :\n",
    "        super().__init__()\n",
    "        # 3x32x32\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),nn.BatchNorm2d(64),nn.ReLU(),\n",
    "            #cfg[0]=3 64x32x32\n",
    "            Bottleneck(64,64,256,down=True,stride=1),\n",
    "            Bottleneck(256,64,256,down=False,stride=1),\n",
    "            Bottleneck(256,64,256,down=False,stride=1),\n",
    "            #cfg[1]=4 256x32x32\n",
    "            Bottleneck(256,128,512,down=True,stride=2),\n",
    "            Bottleneck(512,128,512,down=False,stride=1),\n",
    "            Bottleneck(512,128,512,down=False,stride=1),\n",
    "            Bottleneck(512,128,512,down=False,stride=1),\n",
    "            #cfg[2]=6 512x16x16\n",
    "            Bottleneck(512,256,1024,down=True,stride=2),\n",
    "            Bottleneck(1024,256,1024,down=False,stride=1),\n",
    "            Bottleneck(1024,256,1024,down=False,stride=1),\n",
    "            Bottleneck(1024,256,1024,down=False,stride=1),\n",
    "            Bottleneck(1024,256,1024,down=False,stride=1),\n",
    "            Bottleneck(1024,256,1024,down=False,stride=1),\n",
    "            #cfg[3]=3 1024x8x8\n",
    "            Bottleneck(1024,512,2048,down=True,stride=2),\n",
    "            Bottleneck(2048,512,2048,down=False,stride=1),\n",
    "            Bottleneck(2048,512,2048,down=False,stride=1)\n",
    "            #2048x4x4\n",
    "        )\n",
    "        self.avgpool = nn.AvgPool2d(4,1)\n",
    "        self.fc = nn.Linear(2048, num_classes)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        # See note [TorchScript super()]\n",
    "        ## 3 x32 x 32\n",
    "        x = self.conv(x)\n",
    "        ## 2048x4x4\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9119,
     "status": "ok",
     "timestamp": 1647947091616,
     "user": {
      "displayName": "Lee gwan hui",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09079206913426271362"
     },
     "user_tz": -540
    },
    "id": "O_PneCa2S3Is",
    "outputId": "e0eb0463-d715-4baf-bd0d-51c75b8fe0ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 4: INSTANTIATE MODEL CLASS\n",
      "The number of parameters :  23506499\n",
      "ResNet_50(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Bottleneck(\n",
      "      (relu): ReLU()\n",
      "      (bottleneck): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU()\n",
      "        (6): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (relu): ReLU()\n",
      "      (bottleneck): Sequential(\n",
      "        (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU()\n",
      "        (6): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (relu): ReLU()\n",
      "      (bottleneck): Sequential(\n",
      "        (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU()\n",
      "        (6): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (relu): ReLU()\n",
      "      (bottleneck): Sequential(\n",
      "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU()\n",
      "        (6): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (relu): ReLU()\n",
      "      (bottleneck): Sequential(\n",
      "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU()\n",
      "        (6): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (relu): ReLU()\n",
      "      (bottleneck): Sequential(\n",
      "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU()\n",
      "        (6): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (relu): ReLU()\n",
      "      (bottleneck): Sequential(\n",
      "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU()\n",
      "        (6): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (relu): ReLU()\n",
      "      (bottleneck): Sequential(\n",
      "        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU()\n",
      "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (relu): ReLU()\n",
      "      (bottleneck): Sequential(\n",
      "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU()\n",
      "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (relu): ReLU()\n",
      "      (bottleneck): Sequential(\n",
      "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU()\n",
      "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (relu): ReLU()\n",
      "      (bottleneck): Sequential(\n",
      "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU()\n",
      "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (relu): ReLU()\n",
      "      (bottleneck): Sequential(\n",
      "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU()\n",
      "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (relu): ReLU()\n",
      "      (bottleneck): Sequential(\n",
      "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU()\n",
      "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (relu): ReLU()\n",
      "      (bottleneck): Sequential(\n",
      "        (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU()\n",
      "        (6): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (relu): ReLU()\n",
      "      (bottleneck): Sequential(\n",
      "        (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU()\n",
      "        (6): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (18): Bottleneck(\n",
      "      (relu): ReLU()\n",
      "      (bottleneck): Sequential(\n",
      "        (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU()\n",
      "        (6): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=4, stride=1, padding=0)\n",
      "  (fc): Linear(in_features=2048, out_features=3, bias=True)\n",
      ")\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print('STEP 4: INSTANTIATE MODEL CLASS')\n",
    "#############\n",
    "# CODE HERE #\n",
    "#############\n",
    "\n",
    "model = ResNet_50()\n",
    "num_total_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"The number of parameters : \", num_total_params)\n",
    "#######################\n",
    "#  USE GPU FOR MODEL  #\n",
    "#######################\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(model.to(device))\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTFU8J5Uj9aj"
   },
   "source": [
    "### 2.2 Print test accuracy for every epochs. [1 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1657648,
     "status": "ok",
     "timestamp": 1647948754507,
     "user": {
      "displayName": "Lee gwan hui",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09079206913426271362"
     },
     "user_tz": -540
    },
    "id": "ydsAXR-qj9ak",
    "outputId": "7a4eb956-2759-42a4-bd33-124c2999dafb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 5: INSTANTIATE LOSS CLASS\n",
      "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
      "STEP 7: TRAIN THE MODEL\n",
      "Epochs: 0. Loss: 0.67. Accuracy: 74.20. Elapsed time: 109.87sec\n",
      "Epochs: 1. Loss: 0.71. Accuracy: 69.93. Elapsed time: 109.84sec\n",
      "Epochs: 2. Loss: 0.65. Accuracy: 80.73. Elapsed time: 109.65sec\n",
      "Epochs: 3. Loss: 0.48. Accuracy: 82.77. Elapsed time: 109.84sec\n",
      "Epochs: 4. Loss: 0.24. Accuracy: 84.53. Elapsed time: 109.90sec\n",
      "Epochs: 5. Loss: 0.74. Accuracy: 86.27. Elapsed time: 110.14sec\n",
      "Epochs: 6. Loss: 0.35. Accuracy: 86.57. Elapsed time: 110.70sec\n",
      "Epochs: 7. Loss: 0.06. Accuracy: 85.03. Elapsed time: 111.04sec\n",
      "Epochs: 8. Loss: 0.18. Accuracy: 86.37. Elapsed time: 110.98sec\n",
      "Epochs: 9. Loss: 0.31. Accuracy: 87.03. Elapsed time: 110.94sec\n",
      "Epochs: 10. Loss: 0.12. Accuracy: 84.40. Elapsed time: 110.86sec\n",
      "Epochs: 11. Loss: 0.23. Accuracy: 86.30. Elapsed time: 110.96sec\n",
      "Epochs: 12. Loss: 0.24. Accuracy: 87.40. Elapsed time: 110.90sec\n",
      "Epochs: 13. Loss: 0.07. Accuracy: 86.33. Elapsed time: 111.02sec\n",
      "Epochs: 14. Loss: 0.05. Accuracy: 87.57. Elapsed time: 110.66sec\n"
     ]
    }
   ],
   "source": [
    "print('STEP 5: INSTANTIATE LOSS CLASS')\n",
    "#############\n",
    "# CODE HERE #\n",
    "#############\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print('STEP 6: INSTANTIATE OPTIMIZER CLASS')\n",
    "#############\n",
    "# CODE HERE #\n",
    "#############\n",
    "learning_rate = 1e-2\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum = momentum, weight_decay = weight_decay)\n",
    "\n",
    "print('STEP 7: TRAIN THE MODEL')\n",
    "#############\n",
    "# CODE HERE #\n",
    "#############\n",
    "num_epochs = 15\n",
    "\n",
    "for epoch in range(num_epochs) : \n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        #######################\n",
    "        #  USE GPU FOR MODEL  #\n",
    "        #######################\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images) \n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate Accuracy\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # Iterate through test dataset\n",
    "    for images, labels in test_loader:\n",
    "        #######################\n",
    "        #  USE GPU FOR MODEL  #\n",
    "        #######################\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass only to get logits/output\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Get predictions from the maximum value\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # Total number of labels\n",
    "        total += labels.size(0)\n",
    "\n",
    "        # Total correct predictions\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "    accuracy = 100 * correct.item() / total\n",
    "\n",
    "    end = time.time()\n",
    "    # Print Loss\n",
    "    print('Epochs: {}. Loss: {:.2f}. Accuracy: {:.2f}. Elapsed time: {:.2f}sec'.format(epoch, loss.item(), accuracy, end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YiHX2ZPVS3It"
   },
   "source": [
    " 예상했던 점 : 분명 VGG보다 ResNet이 논문 상으로는 더 빨리 계산되어야 하고 더 높은 정확도를 보여야한다.\n",
    "\n",
    "예상과 달랐던 점 : ResNet이 더 많은 시간이 걸렸다 그 이유로는 모든 layer에 batch normalization을 적용하고 있기 때문인데 이 때문에 parameter 수가 23506499로 VGG16의 14720451보다 더 많아졌기 때문에 더 많은 속도가 걸린다.\n",
    "\n",
    "계선할 점 : initialzation을 잘하면 정확도가 더 높을 수 있다는데 따로 설정하지 않을 시 pytorch 는 default 로 uniform distribution 에서 randomly initialize 해준다고 한다. 정확도를 더 높이기 위해서는 input사진의 밝기등을 일정하게 해주면 더 좋은 결과가 나올수도 있을 것 같다. 또한 CIVAR 10 데이터 셋은 resoluation이 좋지 않은데 이것을 높은 해상도로 변환해주는 알고리즘을 사용하면 결과가 좀더 좋을 것 같다. 또한 ResNet의 경우에서만 한정한다면 여기서는 BatchNormalization을 너무 과도하게 사용했기 때문에 매우 오랜 시간이 걸리는데 이를 적절히 조절하면 좋을 것 같다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ijLYvXKS3It"
   },
   "source": [
    "참고로 하자면 VGG16의 경우에는 GeForce RTX 3060Ti로 실시하였고 \n",
    "ResNet의 경우 GPU 용량 초과로 colab에서 진행하였다. \n",
    "ResNet의 경우 1epoch까지는 돌아갔는데 이 때 걸린 시간은 27s였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DLLAB_lab03_problem.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "deep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0d6ea99b60f74a7fa5c72f5b393a5b76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c64ded6e30454561a975ac0fe18903a9",
      "max": 170498071,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3c28cfe5b3994e899bfbe48b89858c60",
      "value": 170498071
     }
    },
    "36bdc6607a4f46b1a706665ccc12ea4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3c28cfe5b3994e899bfbe48b89858c60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "53d4e1d7887040c392bc702803ae4a7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_628b09986c414679bba5afa5470e1fa9",
      "placeholder": "​",
      "style": "IPY_MODEL_36bdc6607a4f46b1a706665ccc12ea4f",
      "value": " 170499072/? [00:06&lt;00:00, 32665022.60it/s]"
     }
    },
    "628b09986c414679bba5afa5470e1fa9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73b1e9c60bb84e4aa8cd43e284ae333c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "80e94dff268b4b6c8fb1e37675b6b8ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a107658c097d44f3a28b8576544ae43a",
      "placeholder": "​",
      "style": "IPY_MODEL_a3994c9941f74f0a82feca71e676b6ca",
      "value": ""
     }
    },
    "a107658c097d44f3a28b8576544ae43a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a3994c9941f74f0a82feca71e676b6ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c64ded6e30454561a975ac0fe18903a9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f370d7336a2d4f2b837f2d5facd97dc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_80e94dff268b4b6c8fb1e37675b6b8ed",
       "IPY_MODEL_0d6ea99b60f74a7fa5c72f5b393a5b76",
       "IPY_MODEL_53d4e1d7887040c392bc702803ae4a7e"
      ],
      "layout": "IPY_MODEL_73b1e9c60bb84e4aa8cd43e284ae333c"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
