{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eXFfI0wi2OWc"
   },
   "source": [
    "> ### EEE4423: Deep Learning Lab\n",
    "\n",
    "# LAB \\#4: Limitation: Spatial Transformer Network(STN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E_TAt1ul2OWd"
   },
   "source": [
    "<h4><div style=\"text-align: right\"> Due date: April 1, 2022.  </div> <br>\n",
    "<div style=\"text-align: right\"> Please upload your file @ LearnUs by 9 AM in the form of [ID_Name_Lab04.ipynb]. </div></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JAd1A1R52OWe"
   },
   "source": [
    "### *Instructions:*\n",
    "- Write a program implementing a particular algorithm to solve a given problem.   \n",
    "- <span style=\"color:red\">**Report and discuss your results. Analyze the algorithm, theoretically and empirically.**</span> \n",
    "- Each team must write their own answers and codes (<span style=\"color:red\">**if not you will get a F grade**</span>)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7v-RdgrF2OWf"
   },
   "source": [
    "<h2><span style=\"color:blue\">[Insert your ID HERE] [Insert your name HERE]</span> </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2022-03-24T11:22:54.619950Z",
     "iopub.status.busy": "2022-03-24T11:22:54.619380Z",
     "iopub.status.idle": "2022-03-24T11:22:54.639314Z",
     "shell.execute_reply": "2022-03-24T11:22:54.638038Z",
     "shell.execute_reply.started": "2022-03-24T11:22:54.619799Z"
    },
    "id": "QsMlF0RR2OWg",
    "outputId": "6ba88b6c-4541-49f8-e21f-086706c61e66",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This code is written at 2022-03-25 04:19:52.430862\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(\"This code is written at \" + str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SxWW19iY2OWm"
   },
   "source": [
    "## Spatial Transformer Network for classification of distorted MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hzBuF0OV2OWn"
   },
   "source": [
    "## Spatial Transformer Network(STN) [1]\n",
    ">- CNNs are limited by the lack of ability to be spatially invariant to the input data\n",
    ">- Learnable module which explicitly allows the spatial manipulation of data within the network\n",
    ">- This differentiable module can be inserted into existing convolutional architectures\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1GV2Ix6wuikWdq6-tGkZv2vMQbqMokDbf\" alt=\"no_image\" style=\"width: 900px;\"/>\n",
    "\n",
    "### STN module\n",
    ">1. Localization Network\n",
    ">>- With given input feature map, this network outputs the parameters of the spatial transformation (e.g. 6 parameters for affine transformation)\n",
    ">>- Reference for affine transformation : [2],[3] <br>\n",
    ">> <img src=\"http://drive.google.com/uc?export=view&id=1qho08Gzea5qDTpmsnii0rvwiLzwy54K6\" alt=\"no_image\" style=\"width: 900px;\"/>\n",
    "\n",
    ">2. Parameterised sampling grid (Grid generator)\n",
    ">>- Set of points where the input feature map is sampled to produce the transformation which is a output of localization network  \n",
    ">>- Target coordinate and source coordinate are normalised ($ -1\\le(x_i^t, y_i^t)\\le1$,$ -1\\le(x_i^s, y_i^s)\\le1$ )\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1pRWzwevo1KjWi3WIC4K8SCkK4oYCD7FZ\" alt=\"no_image\" style=\"width: 500px;\"/>\n",
    ">3. Differentiable Image Sampling (Sampler)\n",
    ">>- Ouput feature map is produced by differentiable bilinear interpolation with input feature map and parameterised sampling grid\n",
    "    \n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1EjoZ6CVLTD3QNl1CKbg1w3YiNf1CzOmH\" alt=\"no_image\" style=\"width: 900px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2022-03-24T11:22:55.073717Z",
     "iopub.status.busy": "2022-03-24T11:22:55.073385Z",
     "iopub.status.idle": "2022-03-24T11:22:56.645160Z",
     "shell.execute_reply": "2022-03-24T11:22:56.643931Z",
     "shell.execute_reply.started": "2022-03-24T11:22:55.073695Z"
    },
    "id": "0AoHVrM52OWo",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torchvision.utils as v_utils\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import io\n",
    "import requests\n",
    "import os \n",
    "import copy\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2022-03-24T11:22:56.646961Z",
     "iopub.status.busy": "2022-03-24T11:22:56.646683Z",
     "iopub.status.idle": "2022-03-24T11:22:56.673943Z",
     "shell.execute_reply": "2022-03-24T11:22:56.673243Z",
     "shell.execute_reply.started": "2022-03-24T11:22:56.646928Z"
    },
    "id": "g84YJUCD2OWr",
    "outputId": "006c73a3-31d5-4b0c-982d-34a203b6f27a",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3090'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device0 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2022-03-24T11:22:56.675697Z",
     "iopub.status.busy": "2022-03-24T11:22:56.675415Z",
     "iopub.status.idle": "2022-03-24T11:22:56.679122Z",
     "shell.execute_reply": "2022-03-24T11:22:56.678477Z",
     "shell.execute_reply.started": "2022-03-24T11:22:56.675675Z"
    },
    "id": "-gaJ_3Gv2OWv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "batch_size = 256\n",
    "learning_rate = 0.001\n",
    "num_epoch = 60\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HHuhiUfN2OWy"
   },
   "source": [
    "### 1. Dataset (Distorted MNIST, details in Appendix A.4 Distorted MNIST) [1point]\n",
    ">- Generate RTS(rotated, translated, scaled) MNIST \n",
    ">>- Use *torchvision.transforms*\n",
    ">>- Randomly rotating between $-45^\\circ, 45^\\circ$\n",
    ">>- Randomly scaling the digit by a factor of between $0.7,1.2$\n",
    ">>- Placing the digit in a random location in a $40\\times40$ region of image's center\n",
    ">>- Zerp padding to increase image's size for the digit's translation ($80\\times80$ image)\n",
    ">>- Images to tensor \n",
    ">>- Normalize data with MNIST dataset's mean and standard deviation printed in the 5th cell below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tFHJ42zM2OW0"
   },
   "source": [
    "#### 1.1 Write codes for dataset's transformation [1 point]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2022-03-24T11:22:56.680045Z",
     "iopub.status.busy": "2022-03-24T11:22:56.679891Z",
     "iopub.status.idle": "2022-03-24T11:23:03.613166Z",
     "shell.execute_reply": "2022-03-24T11:23:03.611965Z",
     "shell.execute_reply.started": "2022-03-24T11:22:56.680027Z"
    },
    "id": "hJaXUT-12OW1",
    "outputId": "830a480e-708b-4bf5-b508-cfb78023e757",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: DEFINE DATASET\n",
      "MNIST mean:  tensor(0.1307)\n",
      "MNIST std:  tensor(0.3081)\n"
     ]
    }
   ],
   "source": [
    "print('STEP 1: DEFINE DATASET')\n",
    "\n",
    "## 질문 1. mnist data set이 1channel인지 -> 맞다.\n",
    "# 질문 2. normalize의 이유 -> 학습이 더 빠르다., 분포를 맞춰준다.\n",
    "## 질문 4. translate 역할 -> Placing the digit in a random location in a  40×40  region of image's center\n",
    "##-> 첨언을 하자면 28 x 28 을 40x40까지 움직일 수 있으면 40/28은 이쁜 수가 아난데?5. \n",
    "## 질문 5. compose는 구성 순서대로 돌아가나? 그렇다면z zero padding 후에 randomlocation을 돌리는 것이 맞는 것이 아닌가?(질문 4와 연관됨)\n",
    "## 질문 5 답 -> padding을 먼저해라.\n",
    "# 질문 6 transform을 하면 mean값과 분산 값이 변하지 않는가? -> 변하지만 문제는 삼지 않는다.\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Pad(26, fill=0, padding_mode='constant'),\n",
    "    transforms.RandomAffine((-45,45),scale=(0.7,1.2),translate=(0.5,0.5)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Pad(26, fill=0, padding_mode='constant'),\n",
    "    transforms.RandomAffine((-45,45),scale=(0.7,1.2),translate=(0.5,0.5)),    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "])\n",
    "\n",
    "## 질문 3. target_transform의 의미\n",
    "train_dataset = dset.MNIST(root='../dataset/lab04/MNIST', train=True, \n",
    "                        transform=transform_train,\n",
    "                        target_transform=None,\n",
    "                        download=True)\n",
    "test_dataset = dset.MNIST(root='../dataset/lab04/MNIST', train=False, \n",
    "                        transform=transform_test,\n",
    "                        target_transform=None,\n",
    "                        download=False)\n",
    "\n",
    "train_size = len(train_dataset)\n",
    "test_size = len(test_dataset)\n",
    "\n",
    "#dataset mean and std for normalization\n",
    "print('MNIST mean: ',train_dataset.train_data.float().mean()/255)\n",
    "print('MNIST std: ',train_dataset.train_data.float().std()/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2022-03-24T11:23:03.633179Z",
     "iopub.status.busy": "2022-03-24T11:23:03.632685Z",
     "iopub.status.idle": "2022-03-24T11:23:03.640291Z",
     "shell.execute_reply": "2022-03-24T11:23:03.639175Z",
     "shell.execute_reply.started": "2022-03-24T11:23:03.633131Z"
    },
    "id": "dmdruxLV2OW5",
    "outputId": "55ecb3fe-8846-4515-8299-44c879306370",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 60000\n",
      "Test dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "print('Train dataset size: {}'.format(len(train_dataset)))\n",
    "print('Test dataset size: {}'.format(len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 80, 80])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P9PliNxe2OW9"
   },
   "source": [
    "###  Visualize Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2022-03-24T11:23:03.642626Z",
     "iopub.status.busy": "2022-03-24T11:23:03.642072Z",
     "iopub.status.idle": "2022-03-24T11:23:04.162114Z",
     "shell.execute_reply": "2022-03-24T11:23:04.160696Z",
     "shell.execute_reply.started": "2022-03-24T11:23:03.642577Z"
    },
    "id": "D7MVg2wH2OW-",
    "outputId": "e0a1b9cb-c9db-477d-a825-91f0cacd88e7",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure()\n",
    "\n",
    "for i in range(train_size):\n",
    "    sample = train_dataset[i]\n",
    "    figure.add_subplot(1,5,i+1).set_title('Label:{}'.format(sample[1]))\n",
    "    imgplot = plt.imshow((sample[0].squeeze(0).cpu()+1)/2)\n",
    "    if i == 4:\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2022-03-24T11:23:18.076172Z",
     "iopub.status.busy": "2022-03-24T11:23:18.075699Z",
     "iopub.status.idle": "2022-03-24T11:23:18.086294Z",
     "shell.execute_reply": "2022-03-24T11:23:18.084946Z",
     "shell.execute_reply.started": "2022-03-24T11:23:18.076119Z"
    },
    "id": "h9wwuE7t2OXC",
    "outputId": "835d6b06-3445-4404-f5de-6f5869a060f5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 2: LOADING DATASET\n"
     ]
    }
   ],
   "source": [
    "print('STEP 2: LOADING DATASET')\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size, shuffle=True,num_workers=4,drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=batch_size, shuffle=False,num_workers=4,drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WkYr7Cp_2OXG"
   },
   "source": [
    "##  Model\n",
    "### 2. CNN Model Setup (details in Appendix A.4 Distorted MNIST) [3points]\n",
    ">\n",
    ">1. CNN \n",
    ">>- 2 convolutional layers and 2 max-pooling layers before final classification layer\n",
    ">>- Two conv layers have 32 and 64 filters and use ReLU \n",
    ">2. Classifier\n",
    ">>- 2 fully-connected layers and the number of input features to the last layer is 128\n",
    ">>- Also use ReLU as an activation function\n",
    ">3. ST module\n",
    ">>- At the beginning of the network\n",
    ">>- 2 convolutional layer and 2 fully-connected layer in localization network\n",
    ">>- Initialize the *fc_loc*'s final regression layer with identity transformation\n",
    ">>- Produce affine transformation parameters for RTS dataset\n",
    ">>- Reference for grid generator function: [4] <br>\n",
    ">>- Reference for sampler function: [5] <br>\n",
    ">\n",
    "> **++Hint: All learnable parameters' sizes of model are in the 10th cell below** <br>\n",
    "> **++For RTS datasets, the network has average pooling layer after the ST module to downsample the output of the transformer by a factor of 2**\n",
    "\n",
    "| **Layer** | **Kernel size** | **stride** | **padding** |\n",
    "|:---:|:---:|:---:|:---:|\n",
    "| 1st Conv of *cnn* | 9 | 1 | 0 |\n",
    "| 2nd Conv of *cnn* | 7 | 1 | 0 |\n",
    "| 1st Conv of *localization* | 5 | 1 | 0 |\n",
    "| 2nd Conv of *localization* | 5 | 1 | 0 |\n",
    "| AvgPool | 2 | 2 | 0 |\n",
    "| MaxPool | 2 | 2 | 0 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cYHuW3KR2OXH"
   },
   "source": [
    "#### 2.1 Write codes for the model class (STN_CNN) [3 points]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2022-03-24T11:23:24.658238Z",
     "iopub.status.busy": "2022-03-24T11:23:24.657769Z",
     "iopub.status.idle": "2022-03-24T11:23:24.665973Z",
     "shell.execute_reply": "2022-03-24T11:23:24.664633Z",
     "shell.execute_reply.started": "2022-03-24T11:23:24.658187Z"
    },
    "id": "pT5hnJ6l2OXI",
    "outputId": "8ea84272-477f-4eb9-8574-c38f600d70c6",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 3: CREATE MODEL CLASS (STN_CNN)\n"
     ]
    }
   ],
   "source": [
    "print('STEP 3: CREATE MODEL CLASS (STN_CNN)')\n",
    "\n",
    "# tunctional.grid_sample -> sampling\n",
    "\n",
    "# Conv -> Conv -> FC -> RC\n",
    "\n",
    "# input img    (1,80,80)\n",
    "# STN 1st conv (20,76,76) 질문 -> 오픈 소스를 봤는데 STN 다음에서도 conv 다음에서도 maxpooling를 사용하는데? \n",
    "# maxpooling    (20,38,38)\n",
    "# STN 2nd conv (20,34,34) 질문 -> 절대 23120이 나올수 없는데? -> 맨 마지막 maxmpooling을 제거하라 \n",
    "# maxpooling    (20,17,17)\n",
    "# STN output (batch size,23120=20x34x34)\n",
    "# STN fc_loc output (batchsize, 20) -> (batchsize, 6) -> (batchsize, 2,3)\n",
    "# CNN input (32)\n",
    "\n",
    "## 아래 시나리오는 걍 틀림.\n",
    "# 다음 시나리오\n",
    "# input img (1,80,80)\n",
    "# avg pooling (1,40,40)\n",
    "# STN 1st  conv (20,36,36)\n",
    "# STN 2nd  conv (20,32,32)\n",
    "\n",
    "\n",
    "# input img (1,80,80)\n",
    "# STN 1st  conv (20,76,76)\n",
    "# STN 2nd  conv (20,72,72)\n",
    "# avg pooling (20,36,36)\n",
    "\n",
    "class STN_CNN(nn.Module):\n",
    "    def __init__(self) :\n",
    "        super(STN_CNN, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            # (1,40,40)\n",
    "            nn.Conv2d(1, 32, kernel_size=9),nn.MaxPool2d(kernel_size=2, stride=2),nn.ReLU(),\n",
    "            # (32,32,32) -> (32,16,16)\n",
    "            nn.Conv2d(32, 64, kernel_size=7),nn.MaxPool2d(kernel_size=2, stride=2),nn.ReLU()\n",
    "            # (64,10,10) -> (64,5,5)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(1600, 128),nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "        \n",
    "        # Spatial transformer localization-network\n",
    "        self.localization = nn.Sequential(\n",
    "            #(1,80,80)\n",
    "            nn.Conv2d(1, 20, kernel_size=5),\n",
    "            #(20,76,76)\n",
    "            nn.MaxPool2d(2, stride=2),nn.ReLU(True),\n",
    "            #(20,38,38)\n",
    "            nn.Conv2d(20, 20, kernel_size=5),nn.ReLU(True)\n",
    "            #(20,34,34)\n",
    "        )\n",
    "\n",
    "        # Regressor for the 3 * 2 affine matrix\n",
    "        self.fc_loc = nn.Sequential(\n",
    "            nn.Linear(20 * 34 * 34, 20),nn.ReLU(), # 23120 = 20 x34 x34\n",
    "            nn.Linear(20, 6)\n",
    "        )\n",
    "\n",
    "        # Initialize the weights/bias with identity transformation\n",
    "        self.fc_loc[2].weight.data.fill_(0)\n",
    "        self.fc_loc[2].bias.data = torch.FloatTensor([1, 0, 0, 0, 1, 0])\n",
    "        \n",
    "        self.avgpool = nn.AvgPool2d(2, stride=2)\n",
    "\n",
    "    # Spatial transformer network forward function\n",
    "    def stn(self, x):\n",
    "        # input feature map : (1, 80, 80)\n",
    "        xs = self.localization(x)\n",
    "        # localization은 2개의 conv layer를 통과한다.\n",
    "        # output feature map : (20, 34, 34)\n",
    "        # 아래를 통해  20, 34, 34, 이 linear 연산을 할 수 있는 1-D로 변환됨.\n",
    "        xs = xs.view(-1, 20 * 34 * 34)\n",
    "        # theta는 affine 변환을 위한 parameter.\n",
    "        theta = self.fc_loc(xs)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "\n",
    "        grid = F.affine_grid(theta, x.size())\n",
    "        x = F.grid_sample(x, grid)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        # transform the input\n",
    "        # x : input (1, 80, 80)\n",
    "        x = self.stn(x)\n",
    "        # stn 통해 나온 결과는 str의 input과 동일한 size \n",
    "        # 즉 정규화된 이미지라고 생각하면 된다.\n",
    "        x = self.avgpool(x)\n",
    "        # 변형된 input (1,40,40)\n",
    "        # 여기서부터는 일반적인 classification을 위한 forward pass 와 동일\n",
    "        x = self.cnn(x)\n",
    "        x = x.view(-1, 1600)        \n",
    "        x = self.classifier(x)\n",
    "        return F.log_softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2022-03-24T11:23:25.618588Z",
     "iopub.status.busy": "2022-03-24T11:23:25.618032Z",
     "iopub.status.idle": "2022-03-24T11:23:25.648656Z",
     "shell.execute_reply": "2022-03-24T11:23:25.647756Z",
     "shell.execute_reply.started": "2022-03-24T11:23:25.618539Z"
    },
    "id": "IjmaoyEv2OXM",
    "outputId": "bf5a432d-493d-4d2d-d8e6-fc3c8783cde6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 4: INSTANTIATE MODEL CLASS\n",
      "\n",
      "STN_CNN's state_dict:\n",
      "cnn.0.weight \t torch.Size([32, 1, 9, 9])\n",
      "cnn.0.bias \t torch.Size([32])\n",
      "cnn.3.weight \t torch.Size([64, 32, 7, 7])\n",
      "cnn.3.bias \t torch.Size([64])\n",
      "classifier.0.weight \t torch.Size([128, 1600])\n",
      "classifier.0.bias \t torch.Size([128])\n",
      "classifier.2.weight \t torch.Size([10, 128])\n",
      "classifier.2.bias \t torch.Size([10])\n",
      "localization.0.weight \t torch.Size([20, 1, 5, 5])\n",
      "localization.0.bias \t torch.Size([20])\n",
      "localization.3.weight \t torch.Size([20, 20, 5, 5])\n",
      "localization.3.bias \t torch.Size([20])\n",
      "fc_loc.0.weight \t torch.Size([20, 23120])\n",
      "fc_loc.0.bias \t torch.Size([20])\n",
      "fc_loc.2.weight \t torch.Size([6, 20])\n",
      "fc_loc.2.bias \t torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "print('STEP 4: INSTANTIATE MODEL CLASS\\n')\n",
    "model = STN_CNN()\n",
    "\n",
    "print(\"STN_CNN's state_dict:\")\n",
    "os.makedirs('weights/lab04', exist_ok=True)\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SvfNJkk02OXQ"
   },
   "source": [
    "###  Parameter updates\n",
    "#### Scheduling (Annealing) the learning rate [6]\n",
    ">- In training deep networks, it is usually helpful to anneal the learning rate over time\n",
    ">>- With high learning rate, the optimizing system can't settle down into deeper parts of the loss function\n",
    ">- When to decay can be tricky\n",
    ">>- Slowly : Wasting computation with little improvement for a long time\n",
    ">>- Aggressively: Cooling too quickly, unable to find the best point\n",
    ">- 3 common types\n",
    ">>1. Step decay: Reduce the learning rate by some factor every few epochs (e.g. half every 5 epochs, or by 0.1 every 10 epochs)\n",
    ">>2. Exponential decay: In the form of mathematical formulation $\\alpha = \\alpha_0\\exp^{-kt}$, where $\\alpha_0, k$ are hyperparameters and $t$ is the iteration number(or units of epochs)\n",
    ">>3. $1/t$ decay : In the form of mathematical formulation $\\alpha = \\alpha_0/(1+kt)$, where $\\alpha_0, k$ are hyperparameters and $t$ is the iteration number\n",
    ">- In practice, the step decay is slightly preferable\n",
    "\n",
    "#### How to adjust learning rate in pytorch [7]\n",
    ">- *torch.optim.lr_scheduler* provides several methods based on the number of epochs\n",
    ">- For example, the step decay can be implemented by *torch.optim.lr_scheduler.StepLR* class (See reference for more types)\n",
    ">- We use *ReduceLROnPlateau* class in this lab which allows dynamic learning rate adjusting based on our validation measurements\n",
    ">>- Reduce the learning rate when our metric has stopped improving \n",
    ">>- The learning rate is reduced if no improvement of our metric is seen for a 'patience' number of epochs\n",
    ">>- See reference for more details \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 4: INSTANTIATE MODEL CLASS\n",
      "The number of parameters :  782344\n",
      "STN_CNN(\n",
      "  (cnn): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(9, 9), stride=(1, 1))\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(32, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      "  (localization): Sequential(\n",
      "    (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(20, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): ReLU(inplace=True)\n",
      "  )\n",
      "  (fc_loc): Sequential(\n",
      "    (0): Linear(in_features=23120, out_features=20, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=20, out_features=6, bias=True)\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      ")\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print('STEP 4: INSTANTIATE MODEL CLASS')\n",
    "\n",
    "num_total_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"The number of parameters : \", num_total_params)\n",
    "#######################\n",
    "#  USE GPU FOR MODEL  #\n",
    "#######################\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(model.to(device))\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.status.busy": "2022-03-24T11:23:04.166634Z",
     "iopub.status.idle": "2022-03-24T11:23:04.166865Z",
     "shell.execute_reply": "2022-03-24T11:23:04.166749Z",
     "shell.execute_reply.started": "2022-03-24T11:23:04.166739Z"
    },
    "id": "jLusumF82OXR",
    "outputId": "5830bff3-6ed8-41a4-f499-72bab0e13ad8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 5: INSTANTIATE OPTIMIZER CLASS\n"
     ]
    }
   ],
   "source": [
    "print('STEP 5: INSTANTIATE OPTIMIZER CLASS')\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor = 0.1, patience=6)\n",
    "\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vvw4SWmz2OXY"
   },
   "source": [
    "### 3.Train/Test [2points]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bCEa1yPU2OXa"
   },
   "source": [
    "#### 3.1Tirain the STN_CNN model and print accuracy for every epochs [2 points]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.status.busy": "2022-03-24T11:23:04.167706Z",
     "iopub.status.idle": "2022-03-24T11:23:04.167921Z",
     "shell.execute_reply": "2022-03-24T11:23:04.167821Z",
     "shell.execute_reply.started": "2022-03-24T11:23:04.167810Z"
    },
    "id": "GyKtHA002OXb",
    "outputId": "0e82495e-393f-4624-e3c6-afd50cd69968",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 6: INSTANTIATE LOSS CLASS\n",
      "STEP 7: TRAIN THE MODEL\n",
      "Train Epoch: 0 [0/60000 (0%) / Learning rate:0.001]\tLoss:2.305676  \n",
      "Train Epoch: 0 [51200/60000 (85%) / Learning rate:0.001]\tLoss:1.962329  \n",
      "////Epoch elapsed time: 7.80545449256897////\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%) / Learning rate:0.001]\tLoss:1.835403  \n",
      "Train Epoch: 1 [51200/60000 (85%) / Learning rate:0.001]\tLoss:1.404974  \n",
      "////Epoch elapsed time: 7.610682010650635////\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%) / Learning rate:0.001]\tLoss:1.271935  \n",
      "Train Epoch: 2 [51200/60000 (85%) / Learning rate:0.001]\tLoss:1.195376  \n",
      "////Epoch elapsed time: 7.599729061126709////\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%) / Learning rate:0.001]\tLoss:1.053214  \n",
      "Train Epoch: 3 [51200/60000 (85%) / Learning rate:0.001]\tLoss:1.019075  \n",
      "////Epoch elapsed time: 7.534734487533569////\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%) / Learning rate:0.001]\tLoss:1.040569  \n",
      "Train Epoch: 4 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.957519  \n",
      "////Epoch elapsed time: 7.6419901847839355////\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.871893  \n",
      "Train Epoch: 5 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.823977  \n",
      "////Epoch elapsed time: 7.701342582702637////\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.863755  \n",
      "Train Epoch: 6 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.867115  \n",
      "////Epoch elapsed time: 7.688823938369751////\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.883123  \n",
      "Train Epoch: 7 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.845813  \n",
      "////Epoch elapsed time: 7.584315538406372////\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.780050  \n",
      "Train Epoch: 8 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.677090  \n",
      "////Epoch elapsed time: 7.70842432975769////\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.610549  \n",
      "Train Epoch: 9 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.654955  \n",
      "////Epoch elapsed time: 7.481086254119873////\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.566824  \n",
      "Train Epoch: 10 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.619672  \n",
      "////Epoch elapsed time: 7.364072561264038////\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.746160  \n",
      "Train Epoch: 11 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.658847  \n",
      "////Epoch elapsed time: 7.653101444244385////\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.581239  \n",
      "Train Epoch: 12 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.509820  \n",
      "////Epoch elapsed time: 7.62168550491333////\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.605280  \n",
      "Train Epoch: 13 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.611626  \n",
      "////Epoch elapsed time: 7.730657577514648////\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.558927  \n",
      "Train Epoch: 14 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.668190  \n",
      "////Epoch elapsed time: 7.754278898239136////\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.575831  \n",
      "Train Epoch: 15 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.625714  \n",
      "////Epoch elapsed time: 7.6353795528411865////\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.649312  \n",
      "Train Epoch: 16 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.586632  \n",
      "////Epoch elapsed time: 7.581948518753052////\n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.490585  \n",
      "Train Epoch: 17 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.572545  \n",
      "////Epoch elapsed time: 7.761411428451538////\n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.559537  \n",
      "Train Epoch: 18 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.653369  \n",
      "////Epoch elapsed time: 7.445643424987793////\n",
      "\n",
      "Train Epoch: 19 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.575584  \n",
      "Train Epoch: 19 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.617713  \n",
      "////Epoch elapsed time: 7.779289484024048////\n",
      "\n",
      "Train Epoch: 20 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.413292  \n",
      "Train Epoch: 20 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.538658  \n",
      "////Epoch elapsed time: 7.817870378494263////\n",
      "\n",
      "Train Epoch: 21 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.590897  \n",
      "Train Epoch: 21 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.516503  \n",
      "////Epoch elapsed time: 7.386025667190552////\n",
      "\n",
      "Train Epoch: 22 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.457293  \n",
      "Train Epoch: 22 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.506669  \n",
      "////Epoch elapsed time: 7.598750352859497////\n",
      "\n",
      "Train Epoch: 23 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.411200  \n",
      "Train Epoch: 23 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.587188  \n",
      "////Epoch elapsed time: 7.617165803909302////\n",
      "\n",
      "Train Epoch: 24 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.549162  \n",
      "Train Epoch: 24 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.507670  \n",
      "////Epoch elapsed time: 7.7358338832855225////\n",
      "\n",
      "Train Epoch: 25 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.537234  \n",
      "Train Epoch: 25 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.492189  \n",
      "////Epoch elapsed time: 7.5008344650268555////\n",
      "\n",
      "Train Epoch: 26 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.520140  \n",
      "Train Epoch: 26 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.509233  \n",
      "////Epoch elapsed time: 7.52177357673645////\n",
      "\n",
      "Train Epoch: 27 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.473716  \n",
      "Train Epoch: 27 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.499047  \n",
      "////Epoch elapsed time: 7.5102763175964355////\n",
      "\n",
      "Train Epoch: 28 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.459996  \n",
      "Train Epoch: 28 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.456958  \n",
      "////Epoch elapsed time: 7.551578044891357////\n",
      "\n",
      "Train Epoch: 29 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.556368  \n",
      "Train Epoch: 29 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.491976  \n",
      "////Epoch elapsed time: 7.658154487609863////\n",
      "\n",
      "Train Epoch: 30 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.531696  \n",
      "Train Epoch: 30 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.393557  \n",
      "////Epoch elapsed time: 7.772494554519653////\n",
      "\n",
      "Train Epoch: 31 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.442785  \n",
      "Train Epoch: 31 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.382050  \n",
      "////Epoch elapsed time: 8.045954465866089////\n",
      "\n",
      "Train Epoch: 32 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.395593  \n",
      "Train Epoch: 32 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.484040  \n",
      "////Epoch elapsed time: 7.847379684448242////\n",
      "\n",
      "Train Epoch: 33 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.435573  \n",
      "Train Epoch: 33 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.384311  \n",
      "////Epoch elapsed time: 7.685675144195557////\n",
      "\n",
      "Train Epoch: 34 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.404241  \n",
      "Train Epoch: 34 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.483873  \n",
      "////Epoch elapsed time: 7.707061767578125////\n",
      "\n",
      "Train Epoch: 35 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.470588  \n",
      "Train Epoch: 35 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.511673  \n",
      "////Epoch elapsed time: 7.565494060516357////\n",
      "\n",
      "Train Epoch: 36 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.439972  \n",
      "Train Epoch: 36 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.371034  \n",
      "////Epoch elapsed time: 7.782118082046509////\n",
      "\n",
      "Train Epoch: 37 [0/60000 (0%) / Learning rate:0.0001]\tLoss:0.523618  \n",
      "Train Epoch: 37 [51200/60000 (85%) / Learning rate:0.0001]\tLoss:0.456951  \n",
      "////Epoch elapsed time: 7.664713621139526////\n",
      "\n",
      "Train Epoch: 38 [0/60000 (0%) / Learning rate:0.0001]\tLoss:0.363281  \n",
      "Train Epoch: 38 [51200/60000 (85%) / Learning rate:0.0001]\tLoss:0.352477  \n",
      "////Epoch elapsed time: 7.507754802703857////\n",
      "\n",
      "Train Epoch: 39 [0/60000 (0%) / Learning rate:0.0001]\tLoss:0.406295  \n",
      "Train Epoch: 39 [51200/60000 (85%) / Learning rate:0.0001]\tLoss:0.445412  \n",
      "////Epoch elapsed time: 7.57726263999939////\n",
      "\n",
      "Train Epoch: 40 [0/60000 (0%) / Learning rate:0.0001]\tLoss:0.315154  \n",
      "Train Epoch: 40 [51200/60000 (85%) / Learning rate:0.0001]\tLoss:0.343457  \n",
      "////Epoch elapsed time: 7.429585933685303////\n",
      "\n",
      "Train Epoch: 41 [0/60000 (0%) / Learning rate:0.0001]\tLoss:0.348273  \n",
      "Train Epoch: 41 [51200/60000 (85%) / Learning rate:0.0001]\tLoss:0.531713  \n",
      "////Epoch elapsed time: 7.758529186248779////\n",
      "\n",
      "Train Epoch: 42 [0/60000 (0%) / Learning rate:0.0001]\tLoss:0.394111  \n",
      "Train Epoch: 42 [51200/60000 (85%) / Learning rate:0.0001]\tLoss:0.448736  \n",
      "////Epoch elapsed time: 7.599625825881958////\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 43 [0/60000 (0%) / Learning rate:0.0001]\tLoss:0.363580  \n",
      "Train Epoch: 43 [51200/60000 (85%) / Learning rate:0.0001]\tLoss:0.361442  \n",
      "////Epoch elapsed time: 7.360799312591553////\n",
      "\n",
      "Train Epoch: 44 [0/60000 (0%) / Learning rate:0.0001]\tLoss:0.414489  \n",
      "Train Epoch: 44 [51200/60000 (85%) / Learning rate:0.0001]\tLoss:0.387016  \n",
      "////Epoch elapsed time: 7.5319273471832275////\n",
      "\n",
      "Train Epoch: 45 [0/60000 (0%) / Learning rate:0.0001]\tLoss:0.419072  \n",
      "Train Epoch: 45 [51200/60000 (85%) / Learning rate:0.0001]\tLoss:0.363652  \n",
      "////Epoch elapsed time: 7.73002815246582////\n",
      "\n",
      "Train Epoch: 46 [0/60000 (0%) / Learning rate:0.0001]\tLoss:0.428124  \n",
      "Train Epoch: 46 [51200/60000 (85%) / Learning rate:0.0001]\tLoss:0.406991  \n",
      "////Epoch elapsed time: 7.610511302947998////\n",
      "\n",
      "Train Epoch: 47 [0/60000 (0%) / Learning rate:0.0001]\tLoss:0.419095  \n",
      "Train Epoch: 47 [51200/60000 (85%) / Learning rate:0.0001]\tLoss:0.432694  \n",
      "////Epoch elapsed time: 7.744132041931152////\n",
      "\n",
      "Train Epoch: 48 [0/60000 (0%) / Learning rate:0.0001]\tLoss:0.380045  \n",
      "Train Epoch: 48 [51200/60000 (85%) / Learning rate:0.0001]\tLoss:0.370479  \n",
      "////Epoch elapsed time: 7.707335472106934////\n",
      "\n",
      "Train Epoch: 49 [0/60000 (0%) / Learning rate:0.0001]\tLoss:0.489380  \n",
      "Train Epoch: 49 [51200/60000 (85%) / Learning rate:0.0001]\tLoss:0.257450  \n",
      "////Epoch elapsed time: 7.608829498291016////\n",
      "\n",
      "Train Epoch: 50 [0/60000 (0%) / Learning rate:0.0001]\tLoss:0.367676  \n",
      "Train Epoch: 50 [51200/60000 (85%) / Learning rate:0.0001]\tLoss:0.389164  \n",
      "////Epoch elapsed time: 7.777193784713745////\n",
      "\n",
      "Train Epoch: 51 [0/60000 (0%) / Learning rate:0.0001]\tLoss:0.371462  \n",
      "Train Epoch: 51 [51200/60000 (85%) / Learning rate:0.0001]\tLoss:0.428229  \n",
      "////Epoch elapsed time: 7.681408405303955////\n",
      "\n",
      "Train Epoch: 52 [0/60000 (0%) / Learning rate:0.0001]\tLoss:0.349384  \n",
      "Train Epoch: 52 [51200/60000 (85%) / Learning rate:0.0001]\tLoss:0.291668  \n",
      "////Epoch elapsed time: 7.684643268585205////\n",
      "\n",
      "Train Epoch: 53 [0/60000 (0%) / Learning rate:0.0001]\tLoss:0.341386  \n",
      "Train Epoch: 53 [51200/60000 (85%) / Learning rate:0.0001]\tLoss:0.467460  \n",
      "////Epoch elapsed time: 7.59344744682312////\n",
      "\n",
      "Train Epoch: 54 [0/60000 (0%) / Learning rate:0.0001]\tLoss:0.438763  \n",
      "Train Epoch: 54 [51200/60000 (85%) / Learning rate:0.0001]\tLoss:0.434576  \n",
      "////Epoch elapsed time: 7.731200218200684////\n",
      "\n",
      "Train Epoch: 55 [0/60000 (0%) / Learning rate:0.0001]\tLoss:0.345333  \n",
      "Train Epoch: 55 [51200/60000 (85%) / Learning rate:0.0001]\tLoss:0.504815  \n",
      "////Epoch elapsed time: 7.511354923248291////\n",
      "\n",
      "Train Epoch: 56 [0/60000 (0%) / Learning rate:0.0001]\tLoss:0.461782  \n",
      "Train Epoch: 56 [51200/60000 (85%) / Learning rate:0.0001]\tLoss:0.376220  \n",
      "////Epoch elapsed time: 7.560535192489624////\n",
      "\n",
      "Train Epoch: 57 [0/60000 (0%) / Learning rate:0.0001]\tLoss:0.336222  \n",
      "Train Epoch: 57 [51200/60000 (85%) / Learning rate:0.0001]\tLoss:0.436059  \n",
      "////Epoch elapsed time: 7.565564155578613////\n",
      "\n",
      "Train Epoch: 58 [0/60000 (0%) / Learning rate:1e-05]\tLoss:0.363320  \n",
      "Train Epoch: 58 [51200/60000 (85%) / Learning rate:1e-05]\tLoss:0.425976  \n",
      "////Epoch elapsed time: 7.477216005325317////\n",
      "\n",
      "Train Epoch: 59 [0/60000 (0%) / Learning rate:1e-05]\tLoss:0.327083  \n",
      "Train Epoch: 59 [51200/60000 (85%) / Learning rate:1e-05]\tLoss:0.472548  \n",
      "////Epoch elapsed time: 7.547336101531982////\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('STEP 6: INSTANTIATE LOSS CLASS')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Model to GPU\n",
    "model.to(device)\n",
    "\n",
    "print('STEP 7: TRAIN THE MODEL')\n",
    "best_acc = 0\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    #TRAIN\n",
    "    model.train()\n",
    "    start = time.time()\n",
    "    \n",
    "    for j,(img,label) in enumerate(train_loader):\n",
    "        images = img.to(device)\n",
    "        labels = label.to(device)\n",
    "        \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images) \n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        if j % 200 == 0:\n",
    "            #0번째와 200x256(batch size)에서만 출력하겠다. \n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%) / Learning rate:{}]\\tLoss:{:.6f}  '.format(\n",
    "                    epoch, j * len(img), train_size,\n",
    "                    100. * j / len(train_loader),get_lr(optimizer), loss.item()))\n",
    "\n",
    "    #Test\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # Iterate through test dataset\n",
    "    for images, labels in test_loader:\n",
    "\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass only to get logits/output\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Get predictions from the maximum value\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # Total number of labels\n",
    "        total += labels.size(0)\n",
    "\n",
    "        # Total correct predictions\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "    accuracy = 100 * correct.item() / total\n",
    "    # Print Loss\n",
    "    print('////Epoch elapsed time: {}////\\n'.format(time.time() - start))  \n",
    "    \n",
    "    if accuracy > best_acc :\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            'accuracy': accuracy\n",
    "            \n",
    "            }, './weights/lab04/best_model_STN.tar')\n",
    "       \n",
    "        best_acc = accuracy\n",
    "    \n",
    "    scheduler.step(accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yhPP8ATu2OXg"
   },
   "source": [
    "### 4. Visualize original inputs and transformed inputs with best pre-trained model  [3points]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.status.busy": "2022-03-24T11:23:04.168898Z",
     "iopub.status.idle": "2022-03-24T11:23:04.169115Z",
     "shell.execute_reply": "2022-03-24T11:23:04.169010Z",
     "shell.execute_reply.started": "2022-03-24T11:23:04.168999Z"
    },
    "id": "aZj6oLi62OXi",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = STN_CNN()\n",
    "checkpoint = torch.load('./weights/lab04/best_model_STN.tar')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h6WD4pCv2OXk"
   },
   "source": [
    "#### Our pretrained model's best accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.status.busy": "2022-03-24T11:23:04.169841Z",
     "iopub.status.idle": "2022-03-24T11:23:04.170048Z",
     "shell.execute_reply": "2022-03-24T11:23:04.169950Z",
     "shell.execute_reply.started": "2022-03-24T11:23:04.169940Z"
    },
    "id": "UB4GmH2g2OXl",
    "outputId": "83e334ed-b093-4d82-d0be-c29ad5c4ee29",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy of our model with ST module:  87.74038461538461\n"
     ]
    }
   ],
   "source": [
    "print('Best accuracy of our model with ST module: ', checkpoint['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.status.busy": "2022-03-24T11:23:04.171068Z",
     "iopub.status.idle": "2022-03-24T11:23:04.171286Z",
     "shell.execute_reply": "2022-03-24T11:23:04.171183Z",
     "shell.execute_reply.started": "2022-03-24T11:23:04.171171Z"
    },
    "id": "3F5ppqXP2OXr",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tensor image to array image\n",
    "def reprocess_image(img):\n",
    "    \n",
    "    img_re = copy.copy(img.cpu().data.numpy())\n",
    "    \n",
    "    mean = [-0.1307,-0.1307,-0.1307]\n",
    "    std = [1/0.3081,1/0.3081,1/0.3081]\n",
    "    \n",
    "    for c in range(3):\n",
    "        img_re[c,:,:] /= std[c]\n",
    "        img_re[c,:,:] -= mean[c]\n",
    "        \n",
    "    img_re[img_re > 1] = 1\n",
    "    img_re[img_re < 0] = 0\n",
    "    \n",
    "    img_re = img_re.transpose(1,2,0)\n",
    "    \n",
    "    return img_re\n",
    "\n",
    "#made _grid 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "suci-kWM2OXt"
   },
   "source": [
    "#### 4.1 Write codes for visualization of original inputsa and transformed inputs [3 points]\n",
    ">- VisualizeSTN class with an input of our pretrained model\n",
    ">- *forward_stn*: Forward pass of our pretrained STN module to produce transformed inputs\n",
    ">- *visualize*: Visualizing the original inputs and the transformed ones in a grid \n",
    ">>1. Forward pass of STN module to produce the transformed inputs\n",
    ">>2. Unnormalize both images using *reprocess_image* function\n",
    ">>3. Make grids of them \n",
    ">>4. Visualize \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.status.busy": "2022-03-24T11:23:04.172104Z",
     "iopub.status.idle": "2022-03-24T11:23:04.172315Z",
     "shell.execute_reply": "2022-03-24T11:23:04.172214Z",
     "shell.execute_reply.started": "2022-03-24T11:23:04.172203Z"
    },
    "id": "zcdkczCj2OXu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VisualizeSTN():\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.model.to(device)\n",
    "        self.model.eval()\n",
    "    \n",
    "    # Output transformed inputs\n",
    "    def forward_stn(self,x):\n",
    "        self.input_tensor = x.cpu()\n",
    "        self.transformed_input_tensor = model.stn(x).cpu()\n",
    "    \n",
    "    def visualize(self, img):\n",
    "        self.forward_stn(img)\n",
    "        in_grid = reprocess_image(\n",
    "            v_utils.make_grid(self.input_tensor)\n",
    "        )\n",
    "\n",
    "        out_grid = reprocess_image(\n",
    "            v_utils.make_grid(self.transformed_input_tensor)\n",
    "        )\n",
    "        \n",
    "        # Plot the results side-by-side\n",
    "        f, axarr = plt.subplots(1, 2)\n",
    "        axarr[0].imshow(in_grid)\n",
    "        axarr[0].set_title('Dataset Images')\n",
    "\n",
    "        axarr[1].imshow(out_grid)\n",
    "        axarr[1].set_title('Transformed Images')\n",
    "        plt.ioff()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.status.busy": "2022-03-24T11:23:04.172945Z",
     "iopub.status.idle": "2022-03-24T11:23:04.173155Z",
     "shell.execute_reply": "2022-03-24T11:23:04.173056Z",
     "shell.execute_reply.started": "2022-03-24T11:23:04.173045Z"
    },
    "id": "-mkGExZk2OXx",
    "outputId": "b34b0bc7-6b72-407d-a7d1-868e3cbc1aaf",
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torchvision.utils as v_utils\n",
    "\n",
    "\n",
    "visualize_stn = VisualizeSTN(model)\n",
    "for i, (image,label) in enumerate(test_loader):\n",
    "    \n",
    "    img = image[:16].to(device)\n",
    "    visualize_stn.visualize(img)\n",
    "    \n",
    "    if (i+1) == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HEjhSogi2OX0"
   },
   "source": [
    "### 5.Comparison with the cnn model without ST module [1point]\n",
    ">- Model composed of cnn and classifier modules same with our pretrained CNN_STN model \n",
    ">- Use *cnn* and *classifier* modules you implemented \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pecTLkVL2OX0"
   },
   "source": [
    "#### 5.1 Write codes for the model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.status.busy": "2022-03-24T11:23:04.173797Z",
     "iopub.status.idle": "2022-03-24T11:23:04.174007Z",
     "shell.execute_reply": "2022-03-24T11:23:04.173907Z",
     "shell.execute_reply.started": "2022-03-24T11:23:04.173897Z"
    },
    "id": "cnhjymoE2OX2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 2: LOADING DATASET\n",
      "STEP 3: CREATE MODEL CLASS (STN_CNN)\n"
     ]
    }
   ],
   "source": [
    "print('STEP 2: LOADING DATASET')\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size, shuffle=True,num_workers=4,drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=batch_size, shuffle=False,num_workers=4,drop_last=True)\n",
    "\n",
    "print('STEP 3: CREATE MODEL CLASS (STN_CNN)')\n",
    "\n",
    "class CNNWithoutSTN(nn.Module):\n",
    "    def __init__(self) :\n",
    "        super(CNNWithoutSTN, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            # (1,40,40)\n",
    "            nn.Conv2d(1, 32, kernel_size=9),nn.MaxPool2d(kernel_size=2, stride=2),nn.ReLU(),\n",
    "            # (32,32,32) -> (32,16,16)\n",
    "            nn.Conv2d(32, 64, kernel_size=7),nn.MaxPool2d(kernel_size=2, stride=2),nn.ReLU()\n",
    "            # (64,10,10) -> (64,5,5)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(1600, 128),nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "        \n",
    "        self.avgpool = nn.AvgPool2d(2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # transform the input\n",
    "        # x : input (1, 80, 80)\n",
    "        x = self.avgpool(x)\n",
    "        # 변형된 input (1,40,40)\n",
    "        # 여기서부터는 일반적인 classification을 위한 forward pass 와 동일\n",
    "        x = self.cnn(x)\n",
    "        x = x.view(-1, 1600)        \n",
    "        x = self.classifier(x)\n",
    "        return F.log_softmax(x,dim=1)\n",
    "\n",
    "# St moudle만 없고 나머지는 같게 실험만해봐라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.status.busy": "2022-03-24T11:23:04.174904Z",
     "iopub.status.idle": "2022-03-24T11:23:04.175115Z",
     "shell.execute_reply": "2022-03-24T11:23:04.175016Z",
     "shell.execute_reply.started": "2022-03-24T11:23:04.175006Z"
    },
    "id": "M0dtTNMV2OX4",
    "outputId": "a6c0f479-8a8c-425b-ae7d-ca71e688e5be",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 4: INSTANTIATE MODEL CLASS\n",
      "\n",
      "CNN's state_dict:\n",
      "cnn.0.weight \t torch.Size([32, 1, 9, 9])\n",
      "cnn.0.bias \t torch.Size([32])\n",
      "cnn.3.weight \t torch.Size([64, 32, 7, 7])\n",
      "cnn.3.bias \t torch.Size([64])\n",
      "classifier.0.weight \t torch.Size([128, 1600])\n",
      "classifier.0.bias \t torch.Size([128])\n",
      "classifier.2.weight \t torch.Size([10, 128])\n",
      "classifier.2.bias \t torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print('STEP 4: INSTANTIATE MODEL CLASS\\n')\n",
    "model_nostn = CNNWithoutSTN()\n",
    "\n",
    "print(\"CNN's state_dict:\")\n",
    "os.makedirs('weights/lab04', exist_ok=True)\n",
    "for param_tensor in model_nostn.state_dict():\n",
    "    print(param_tensor, \"\\t\", model_nostn.state_dict()[param_tensor].size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.status.busy": "2022-03-24T11:23:04.176083Z",
     "iopub.status.idle": "2022-03-24T11:23:04.176303Z",
     "shell.execute_reply": "2022-03-24T11:23:04.176195Z",
     "shell.execute_reply.started": "2022-03-24T11:23:04.176185Z"
    },
    "id": "RTHfuIMJ2OX7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 5: INSTANTIATE OPTIMIZER CLASS\n"
     ]
    }
   ],
   "source": [
    "print('STEP 5: INSTANTIATE OPTIMIZER CLASS')\n",
    "\n",
    "optimizer = torch.optim.Adam(model_nostn.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor = 0.1, patience=6)\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y-jXzO1Y2OX-",
    "tags": []
   },
   "source": [
    "#### 5.2 Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.status.busy": "2022-03-24T11:23:04.177021Z",
     "iopub.status.idle": "2022-03-24T11:23:04.177236Z",
     "shell.execute_reply": "2022-03-24T11:23:04.177134Z",
     "shell.execute_reply.started": "2022-03-24T11:23:04.177124Z"
    },
    "id": "B1oDqtGl2OX_",
    "outputId": "f7052aca-d4bc-425c-80d4-0ec8142a84e9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 6: INSTANTIATE LOSS CLASS\n",
      "STEP 7: TRAIN THE MODEL\n",
      "Train Epoch: 0 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.474862  \n",
      "Train Epoch: 0 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.318113  \n",
      "////Epoch elapsed time: 7.814685344696045////\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.414392  \n",
      "Train Epoch: 1 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.411988  \n",
      "////Epoch elapsed time: 7.755126953125////\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.411407  \n",
      "Train Epoch: 2 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.382838  \n",
      "////Epoch elapsed time: 7.521145820617676////\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.407773  \n",
      "Train Epoch: 3 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.400869  \n",
      "////Epoch elapsed time: 7.585670709609985////\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.450286  \n",
      "Train Epoch: 4 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.394029  \n",
      "////Epoch elapsed time: 7.6746509075164795////\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.375799  \n",
      "Train Epoch: 5 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.386436  \n",
      "////Epoch elapsed time: 7.494521617889404////\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.363109  \n",
      "Train Epoch: 6 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.470792  \n",
      "////Epoch elapsed time: 7.345250368118286////\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.395487  \n",
      "Train Epoch: 7 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.379444  \n",
      "////Epoch elapsed time: 7.42273473739624////\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.401329  \n",
      "Train Epoch: 8 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.429080  \n",
      "////Epoch elapsed time: 7.510607719421387////\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.368415  \n",
      "Train Epoch: 9 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.443375  \n",
      "////Epoch elapsed time: 7.735255002975464////\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.323555  \n",
      "Train Epoch: 10 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.366764  \n",
      "////Epoch elapsed time: 7.6404149532318115////\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.332649  \n",
      "Train Epoch: 11 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.418428  \n",
      "////Epoch elapsed time: 7.456894159317017////\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%) / Learning rate:0.001]\tLoss:0.391343  \n",
      "Train Epoch: 12 [51200/60000 (85%) / Learning rate:0.001]\tLoss:0.384670  \n",
      "////Epoch elapsed time: 7.556494951248169////\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%) / Learning rate:0.0001]\tLoss:0.377941  \n",
      "Train Epoch: 13 [51200/60000 (85%) / Learning rate:0.0001]\tLoss:0.507720  \n",
      "////Epoch elapsed time: 7.579466342926025////\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%) / Learning rate:0.0001]\tLoss:0.425569  \n",
      "Train Epoch: 14 [51200/60000 (85%) / Learning rate:0.0001]\tLoss:0.364858  \n",
      "////Epoch elapsed time: 7.4050562381744385////\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%) / Learning rate:0.0001]\tLoss:0.379236  \n",
      "Train Epoch: 15 [51200/60000 (85%) / Learning rate:0.0001]\tLoss:0.557577  \n",
      "////Epoch elapsed time: 7.532006025314331////\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%) / Learning rate:0.0001]\tLoss:0.323166  \n",
      "Train Epoch: 16 [51200/60000 (85%) / Learning rate:0.0001]\tLoss:0.406141  \n",
      "////Epoch elapsed time: 7.54067587852478////\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('STEP 6: INSTANTIATE LOSS CLASS')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Model to GPU\n",
    "model.to(device)\n",
    "\n",
    "print('STEP 7: TRAIN THE MODEL')\n",
    "best_acc = 0\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    #TRAIN\n",
    "    model.train()\n",
    "    start = time.time()\n",
    "    \n",
    "    for j,(img,label) in enumerate(train_loader):\n",
    "        images = img.to(device)\n",
    "        labels = label.to(device)\n",
    "        \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images) \n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        if j % 200 == 0:\n",
    "            #0번째와 200x256(batch size)에서만 출력하겠다. \n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%) / Learning rate:{}]\\tLoss:{:.6f}  '.format(\n",
    "                    epoch, j * len(img), train_size,\n",
    "                    100. * j / len(train_loader),get_lr(optimizer), loss.item()))\n",
    "\n",
    "    #Test\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # Iterate through test dataset\n",
    "    for images, labels in test_loader:\n",
    "\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass only to get logits/output\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Get predictions from the maximum value\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # Total number of labels\n",
    "        total += labels.size(0)\n",
    "\n",
    "        # Total correct predictions\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "    accuracy = 100 * correct.item() / total\n",
    "    # Print Loss\n",
    "    print('////Epoch elapsed time: {}////\\n'.format(time.time() - start))  \n",
    "    \n",
    "    if accuracy > best_acc :\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            'accuracy': accuracy\n",
    "            \n",
    "            }, './weights/lab04/best_model_CNNWithoutSTN.tar')\n",
    "       \n",
    "        best_acc = accuracy\n",
    "    \n",
    "    scheduler.step(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EgPo5F4x2OYC"
   },
   "source": [
    "#### Best accuracy of the model without ST module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.status.busy": "2022-03-24T11:23:04.177951Z",
     "iopub.status.idle": "2022-03-24T11:23:04.178163Z",
     "shell.execute_reply": "2022-03-24T11:23:04.178062Z",
     "shell.execute_reply.started": "2022-03-24T11:23:04.178051Z"
    },
    "id": "UAd8_Ss42OYC",
    "outputId": "bcd5d035-87c3-4d1e-b580-8c565d463798"
   },
   "outputs": [],
   "source": [
    "print('Best accuracy of our model without ST module: ', best_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LLpVgYys2OYF"
   },
   "source": [
    "### *References*\n",
    "[1] https://arxiv.org/pdf/1506.02025.pdf <br>\n",
    "[2] https://en.wikipedia.org/wiki/Affine_transformation <br>\n",
    "[3] https://en.wikipedia.org/wiki/Transformation_matrix#Affine_transformations <br>\n",
    "[4] https://pytorch.org/docs/stable/nn.html#affine-grid <br>\n",
    "[5] https://pytorch.org/docs/stable/nn.html#torch.nn.functional.grid_sample <br>\n",
    "[6] http://cs231n.github.io/neural-networks-3/#anneal <br>\n",
    "[7] https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate <br>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "EEE4423_lab5_STN_problem.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "torch1.9.0-py3.8-cuda11.1",
   "language": "python",
   "name": "torch1.9.0-py3.8-cuda11.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
