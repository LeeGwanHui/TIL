{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clIFh_guHNFv"
   },
   "source": [
    "> ### EEE4423: Deep Learning Lab\n",
    "\n",
    "# LAB \\#11: Character Generation using LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Un-_JnG1HNF1"
   },
   "source": [
    "<h4><div style=\"text-align: right\"> Due date: May 20, 2022. </div> <br>\n",
    "<div style=\"text-align: right\"> Please upload your file @ LearnUs by 9 AM in the form of [ID_Name_Lab11.ipynb]. </div></h4>\n",
    "\n",
    "### *Instructions:*\n",
    "- Write a program implementing a particular algorithm to solve a given problem.   \n",
    "- <span style=\"color:red\">**Report and discuss your results. Analyze the algorithm, theoretically and empirically.**</span> \n",
    "- Each team must write their own answers and codes (<span style=\"color:red\">**if not you will get a F grade**</span>)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nats-XhJHNF2"
   },
   "source": [
    "<h2><span style=\"color:blue\">[201714216] [이관희]</span> </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DUNE2wXfHNF2",
    "outputId": "cf8804ce-9063-463d-988f-cd900bd149b1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This code is written at 2022-05-19 00:39:51.082236\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(\"This code is written at \" + str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unidecode in /home/jovyan/.local/lib/python3.8/site-packages (1.3.4)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.3; however, version 22.1 is available.\n",
      "You should consider upgrading via the '/home/jovyan/.venv/torch1.9.0-py3.8-cuda11.1/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install unidecode --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "J8vQvyjWHNF5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9OP9XM9HNF5"
   },
   "source": [
    "These sorts of generative models form the basis of machine translation, image captioning, question answering and more.\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=16E7HG_dCyfTo9u9qrrhp2eClq6xK6-f_\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6YQl92mwHNF6"
   },
   "source": [
    "### 1. Prepare data\n",
    "\n",
    "The file we are using is a plain text file. We turn any potential unicode characters into plain ASCII by using the `unidecode` package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ymNU_-ZGHNF6"
   },
   "source": [
    "<img src=\"http://drive.google.com/uc?export=view&id=171lX3vxj60AQNScQi872BHx2Rz6J7-3J\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "TFK9sT_1HNF6",
    "outputId": "1bbcf9b6-7367-4aba-ff59-7a3e6134441d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_len = 4063\n"
     ]
    }
   ],
   "source": [
    "# 파일 불러오기 \n",
    "file = unidecode.unidecode(open('../dataset/lab11/lose_yourself_eminem.txt').read())\n",
    "file_len = len(file)\n",
    "print('file_len =', file_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUyRw-C2HNF6"
   },
   "source": [
    "To make inputs out of this big string of data, we will be splitting it into chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6nPqv8tuHNF7",
    "outputId": "2a05a019-0267-43fd-9e6a-cbcf9c5ac4c3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chmo who flows, he nose dove and sold nada\n",
      "So the soap opera is told and unfolds, I suppose it's old partna, but the beat goes on\n",
      "Da da dumb da dumb da da\n",
      "You better lose yourself in the music, the mom\n",
      "\n",
      "\n",
      "201\n"
     ]
    }
   ],
   "source": [
    "chunk_len = 200\n",
    "\n",
    "# train과 test에서 사용할 data가 매우 길이가 제각각이므로 이를 일정하게 만드는 역할이다.\n",
    "# 아래 출력값의 글자수가 200이되는 것이다.\n",
    "def random_chunk():\n",
    "    start_index = random.randint(0, file_len - chunk_len)\n",
    "    # print(start_index)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "print(random_chunk())\n",
    "print('\\n')\n",
    "print(len(random_chunk()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ScRzeDr8HNF9"
   },
   "source": [
    "Each chunk will be turned into a tensor by looping through the characters of the string and looking up the index of each character in `all_characters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TylqhpuyHNF9",
    "outputId": "9e4b9d7e-bea0-41a5-d853-caaa711be679",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\r",
      "\u000b",
      "\f",
      "\n",
      "\n",
      "\n",
      "num_chars =  100\n"
     ]
    }
   ],
   "source": [
    "# Turn string into list of longs\n",
    "# 출력가능한 모든 문자를 살펴보자\n",
    "# 여기서 만약 one-hot-vector로 전환한다면 dimension의 크기와 같은 값일 것이다.\n",
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "print(all_characters)\n",
    "print('\\n')\n",
    "print('num_chars = ', n_characters)\n",
    "# 총 올수 있는 문자의 종류는 100개이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcDEF is changed to  tensor([10, 11, 12, 39, 40, 41])\n"
     ]
    }
   ],
   "source": [
    "# 문자열을 input으로 받는다면 그 값을 위에 printable에 해당하는\n",
    "# index tensor로 바꿔주는 역할을 한다. \n",
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = all_characters.index(string[c])\n",
    "    return Variable(tensor)\n",
    "\n",
    "print('abcDEF is changed to ', char_tensor('abcDEF'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b1XvIwnaHNF9"
   },
   "source": [
    "Finally we can assemble a pair of input and target tensors for training, from a random chunk. The input will be all characters *up to the last*, and the target will be all characters *from the first*. So if our chunk is \"abc\" the input will correspond to \"ab\" while the target is \"bc\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "YfaPPbDMHNF-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# love_yourself 가사를 적절하게 자르고 이를\n",
    "# train data와 test data로 나누는 작업이다.\n",
    "def random_training_set():    \n",
    "    chunk = random_chunk()\n",
    "    # print(len(chunk)) # 201 이다 왜냐하면 {end-start}(200)+1을 해야 되므로 \n",
    "    inputs = char_tensor(chunk[:-1])\n",
    "    #print(inputs.size()) torch.Size([200])\n",
    "    targets = char_tensor(chunk[1:])\n",
    "    #print(targets.size()) torch.Size([200])\n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([16, 14, 96, 37, 30, 29, 94, 44, 94, 20, 14, 25, 29, 94, 27, 17, 34, 22,\n",
      "        18, 23, 68, 94, 10, 23, 13, 94, 28, 29, 14, 25, 32, 27, 18, 29, 18, 23,\n",
      "        68, 94, 29, 17, 14, 94, 23, 14, 33, 29, 94, 12, 18, 25, 17, 14, 27, 96,\n",
      "        37, 14, 28, 29, 94, 11, 14, 21, 18, 14, 31, 14, 94, 28, 24, 22, 14, 11,\n",
      "        24, 13, 34, 68, 28, 94, 25, 10, 34, 18, 23, 68, 94, 29, 17, 14, 94, 25,\n",
      "        18, 14, 13, 94, 25, 18, 25, 14, 27, 96, 36, 21, 21, 94, 29, 17, 14, 94,\n",
      "        25, 10, 18, 23, 94, 18, 23, 28, 18, 13, 14, 94, 10, 22, 25, 21, 18, 15,\n",
      "        18, 14, 13, 94, 11, 34, 94, 29, 17, 14, 96, 41, 10, 12, 29, 94, 29, 17,\n",
      "        10, 29, 94, 44, 94, 12, 10, 23, 68, 29, 94, 16, 14, 29, 94, 11, 34, 94,\n",
      "        32, 18, 29, 17, 94, 22, 34, 94, 23, 18, 23, 14, 94, 29, 24, 96, 41, 18,\n",
      "        31, 14, 94, 10, 23, 13, 94, 44, 94, 12, 10, 23, 68, 29, 94, 25, 27, 24,\n",
      "        31, 18])\n",
      "tensor([14, 96, 37, 30, 29, 94, 44, 94, 20, 14, 25, 29, 94, 27, 17, 34, 22, 18,\n",
      "        23, 68, 94, 10, 23, 13, 94, 28, 29, 14, 25, 32, 27, 18, 29, 18, 23, 68,\n",
      "        94, 29, 17, 14, 94, 23, 14, 33, 29, 94, 12, 18, 25, 17, 14, 27, 96, 37,\n",
      "        14, 28, 29, 94, 11, 14, 21, 18, 14, 31, 14, 94, 28, 24, 22, 14, 11, 24,\n",
      "        13, 34, 68, 28, 94, 25, 10, 34, 18, 23, 68, 94, 29, 17, 14, 94, 25, 18,\n",
      "        14, 13, 94, 25, 18, 25, 14, 27, 96, 36, 21, 21, 94, 29, 17, 14, 94, 25,\n",
      "        10, 18, 23, 94, 18, 23, 28, 18, 13, 14, 94, 10, 22, 25, 21, 18, 15, 18,\n",
      "        14, 13, 94, 11, 34, 94, 29, 17, 14, 96, 41, 10, 12, 29, 94, 29, 17, 10,\n",
      "        29, 94, 44, 94, 12, 10, 23, 68, 29, 94, 16, 14, 29, 94, 11, 34, 94, 32,\n",
      "        18, 29, 17, 94, 22, 34, 94, 23, 18, 23, 14, 94, 29, 24, 96, 41, 18, 31,\n",
      "        14, 94, 10, 23, 13, 94, 44, 94, 12, 10, 23, 68, 29, 94, 25, 27, 24, 31,\n",
      "        18, 13])\n"
     ]
    }
   ],
   "source": [
    "inputs , targets =random_training_set()\n",
    "print(inputs)\n",
    "print(targets)\n",
    "# 여기서 학습 방법을 파악해야 한다. inputs의 하나씩 넣은 output 값과 target값을 cross entropy 취해서 학습시켜준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uaQ88mGNHNF-"
   },
   "source": [
    "### 2. Build the LSTM model [4 points]\n",
    "\n",
    "#### [Diagram of LSTM]\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1baQ6Ffu-vDcXbOEBYGeLzhmfvaj4DGgW\" style=\"width: 800px;\"/>\n",
    "LSTM consists of cell state, hidden state and 3 gates that modify or use the cell state. The cell state is the key part of the LSTM and you can think that information \"flows\" in there. The operation of 3 gates are described in below.\n",
    "\n",
    "#### [Forget Gate]\n",
    "The forget gate determines which information in the cell state should be erased.\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1sJisl5P0hggmvH4qrcYgSETFKdFdBSH_\" style=\"width: 600px;\"/>\n",
    "\n",
    "#### [Input Gate]\n",
    "First, the candidate cell state is created using the current input and the previous hidden state. And the input gate determines how much the candidate cell state is reflected to the cell state.\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1Df-k5FORGH7PnXauYcb8qqUpY3Uot9A7\" style=\"width: 600px;\"/>\n",
    "\n",
    "#### [Output Gate]\n",
    "The output gate determines which elements should be extracted from the cell state to produce the output.\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1JLCGPcrZLOYfjyJhMTvmfixHq5plFj8L\" style=\"width: 600px;\"/>\n",
    "\n",
    "The above expression is summarized as follows,\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1kGq8DwwzizuNcg6GF0GaP1DAu26FFlrB\" style=\"width: 300px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "my4efNewHNF-"
   },
   "source": [
    "This model will take as input the character for step $t_{-1}$ and is expected to output the next character $t$. There are three layers - one linear layer that encodes the input character into an internal state, one LSTM layer that operates on that internal state and a hidden state, and a decoder layer that outputs the probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN 구조를 한번 파악해보자. 이걸 알아야 embedding이 어떻게 쓰이는지 파악할 수 있다.\n",
    "\n",
    "'''\n",
    "STEP 3: CREATE MODEL CLASS\n",
    "'''\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.embedding_size = hidden_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # encoder layer인 embedding이 이 함수의 핵심이다.\n",
    "        # https://wikidocs.net/64779 사이트를 참고하자.\n",
    "        # 간단히 말하면 nn.Embedding()을 사용하여 학습가능한 임베딩 테이블을 만드는 것이다.\n",
    "        # 학습 부분을 보면 알겠지만 하나의 element를 조금 변형해서 넣어주는 것 뿐이 없다.\n",
    "        # 즉 embedding은 table을 만드는 함수로 one-hot-encoding 대신 사용할 수 있는 학습 테이블 이라고 보면 된다.\n",
    "        self.encoder = nn.Embedding(self.input_size, self.hidden_size)\n",
    "        self.rnn = nn.RNN(self.embedding_size,self.hidden_size,self.num_layers)\n",
    "        self.decoder = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        # print(input.dtype) # torch.int64\n",
    "        out = self.encoder(input.view(1,-1))\n",
    "        out,hidden = self.rnn(out,hidden)\n",
    "        # print(out.size()) # torch.Size([1, 1, 100])\n",
    "        out = self.decoder(out.view(batch_size,-1))\n",
    "        #print(out.size()) # torch.Size([1, 100])\n",
    "        return out,hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        return hidden\n",
    "\n",
    "hidden_size=100\n",
    "num_layers = 1\n",
    "batch_size = 1\n",
    "    \n",
    "model = RNN(n_characters, hidden_size, hidden_size, n_characters, num_layers)\n",
    "# model = LSTMModel(n_characters, hidden_dim, n_layers, n_characters)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 코드를 이용해서 밑에 내 코드가 잘 짜야져있는지 확인해보자. \n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers=1):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.encoder = nn.Embedding(self.input_size, self.embedding_size)\n",
    "        self.rnn = nn.LSTM(self.embedding_size,self.hidden_size,self.num_layers)\n",
    "        self.decoder = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "    \n",
    "    def forward(self, input, hidden, cell):\n",
    "        out = self.encoder(input.view(1,-1))\n",
    "        out,(hidden,cell) = self.rnn(out,(hidden,cell))\n",
    "        out = self.decoder(out.view(batch_size,-1))\n",
    "        return out,hidden,cell\n",
    "\n",
    "    def init_hidden(self):\n",
    "        hidden = torch.zeros(self.num_layers,batch_size,self.hidden_size)\n",
    "        cell = torch.zeros(self.num_layers,batch_size,self.hidden_size)\n",
    "        return hidden,cell\n",
    "\n",
    "hidden_size = 100\n",
    "num_layers = 1\n",
    "n_characters = len(all_characters)\n",
    "embedding_size=70 \n",
    "batch_size = 1\n",
    "\n",
    "\n",
    "model = LSTM(n_characters, embedding_size, hidden_size, n_characters, num_layers)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (encoder): Embedding(100, 100)\n",
       "  (forget_gate): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (input_gate_i): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (input_gate_C): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (output_gate): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (tanh): Tanh()\n",
       "  (decoder): Linear(in_features=100, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 내가 짠 모델이다.\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_dim, hidden_dim)\n",
    "        \n",
    "        # lstm\n",
    "        # The size of input is (batch_size, seq_dim, hidden_dim)\n",
    "        # 위에께 들어오는지 알았는데 forword에 들어올 input은 그냥 하나의 tensor이다. 이걸 embedding을 통해서\n",
    "        # 학습가능한 형태의 table로 만들어줘야 하는 것이다. 여기서 input_dim = 100 이고 hidden_dim=100이다.\n",
    "        # 즉 100 x 100의 table을 만든것이다.여기서 encoder\n",
    "\n",
    "        \n",
    "        # x size [1] embedding -> [1,100(word의 갯수),100(알바벳 갯수)]\n",
    "        # h size [B,S,C] -> [1,100,100]\n",
    "        # x와 h concatnate 한 size [1,100,200]\n",
    "        # concatnate 못함 왜냐 [1,100,100] 유지해야 되는데 [1,100,200]으로 계산 못함.\n",
    "        # 고로 더하기로 구현하자.\n",
    "        # torch.cat((x, h), 3)\n",
    "        \n",
    "        # forget_gate\n",
    "        self.forget_gate = nn.Linear(hidden_dim, hidden_dim)\n",
    "        \n",
    "        #input_gate\n",
    "        self.input_gate_i = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.input_gate_C = nn.Linear(hidden_dim, hidden_dim)\n",
    "        \n",
    "        ##output_gate\n",
    "        self.output_gate = nn.Linear(input_dim,hidden_dim)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "        self.decoder = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, input, hn, cn):\n",
    "        #############\n",
    "        # CODE HERE #\n",
    "        #############\n",
    "#         print('input : {}'.format(input.size()))\n",
    "#         print('hn : {}'.format(hn.size()))\n",
    "        x = self.encoder(input.view(1,-1)) # x size 1 , 1 -> 1,1,100\n",
    "        # print(x.size())\n",
    "#         print('x : {}'.format(x.size()))\n",
    "        \n",
    "        ## forget Gate\n",
    "        f_t=self.sigmoid(self.forget_gate(x)+self.forget_gate(hn)) # [1,1,100]\n",
    "#         print(f_t.size())\n",
    "        # f_t size [B,hidden_dim]\n",
    "        \n",
    "#         ## 질문 forget gate에서 같은 layer을 의미하는가? ㅇㅇ 공유함. 식이 같음.\n",
    "#         hidden_1= self.forget_gate_input(input) + self.forget_gate_h(hn)\n",
    "#         hidden_1 = self.sigmoid(hidden_1)\n",
    "        \n",
    "        ## input gate\n",
    "        i_t=self.sigmoid(self.input_gate_i(x)+self.input_gate_i(hn))      #[1,1,100]  \n",
    "        tillde_C = self.tanh(self.input_gate_C(x)+self.input_gate_C(hn)) # [1,1,100]\n",
    "        \n",
    "        ## cn 업데이트\n",
    "        cn = cn*f_t+i_t*tillde_C # [1,1,100]\n",
    "#         print(cn.size())\n",
    "        \n",
    "        ## output gate\n",
    "        o_t = self.sigmoid(self.output_gate(x)+self.output_gate(hn))\n",
    "        h_t = o_t * self.tanh(cn)\n",
    "        \n",
    "        # hn 업데이트\n",
    "        hn = h_t # [1,1,100]\n",
    "        \n",
    "        ## 질문 output은 h_t와 같나? 다르다. 여기서 output은 decoder 해줘야함.\n",
    "        output = self.decoder(h_t.view(1,-1)) # [1,100]\n",
    "        return output, hn, cn\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # The size of h0, c0 should be (layer_dim, batch_size, hidden_dim)\n",
    "        #############\n",
    "        # CODE HERE #\n",
    "        #############\n",
    "        h0 = Variable(torch.zeros(self.layer_dim, 1, self.hidden_dim).cuda()) # initial hidden state [1,1,100]\n",
    "        c0 = Variable(torch.zeros(self.layer_dim, 1, self.hidden_dim).cuda()) # initial cell state [1,1,100]\n",
    "        \n",
    "        return h0, c0\n",
    "    \n",
    "hidden_dim = 100\n",
    "n_layers = 1\n",
    "n_characters = len(all_characters)\n",
    "\n",
    "model = LSTMModel(n_characters, hidden_dim, n_layers, n_characters)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (encoder): Embedding(100, 100)\n",
       "  (forget_gate_x): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (forget_gate_h): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (input_gate_i_x): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (input_gate_i_h): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (input_gate_C_x): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (input_gate_C_h): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (output_gate_x): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (output_gate_h): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (tanh): Tanh()\n",
       "  (decoder): Linear(in_features=100, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 위에꺼는 x와 h의 parameter가 같다. 그래서 이게 맞는 모델이다.\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_dim, hidden_dim)\n",
    "        \n",
    "        # lstm\n",
    "        # The size of input is (batch_size, seq_dim, hidden_dim)\n",
    "        # 위에께 들어오는지 알았는데 forword에 들어올 input은 그냥 하나의 tensor이다. 이걸 embedding을 통해서\n",
    "        # 학습가능한 형태의 table로 만들어줘야 하는 것이다. 여기서 input_dim = 100 이고 hidden_dim=100이다.\n",
    "        # 즉 100 x 100의 table을 만든것이다.여기서 encoder\n",
    "\n",
    "        \n",
    "        # x size [1] embedding -> [1,100(word의 갯수),100(알바벳 갯수)]\n",
    "        # h size [B,S,C] -> [1,100,100]\n",
    "        # x와 h concatnate 한 size [1,100,200]\n",
    "        # concatnate 못함 왜냐 [1,100,100] 유지해야 되는데 [1,100,200]으로 계산 못함.\n",
    "        # 고로 더하기로 구현하자.\n",
    "        # torch.cat((x, h), 3)\n",
    "        \n",
    "        # forget_gate\n",
    "        self.forget_gate_x = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.forget_gate_h = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "        #input_gate\n",
    "        self.input_gate_i_x = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.input_gate_i_h = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "        self.input_gate_C_x = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.input_gate_C_h = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "        \n",
    "        ##output_gate\n",
    "        self.output_gate_x = nn.Linear(input_dim,hidden_dim)\n",
    "        self.output_gate_h = nn.Linear(input_dim,hidden_dim)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "        self.decoder = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, input, hn, cn):\n",
    "        #############\n",
    "        # CODE HERE #\n",
    "        #############\n",
    "#         print('input : {}'.format(input.size()))\n",
    "#         print('hn : {}'.format(hn.size()))\n",
    "        x = self.encoder(input.view(1,-1)) # x size 1 , 1 -> 1,1,100\n",
    "        # print(x.size())\n",
    "#         print('x : {}'.format(x.size()))\n",
    "        \n",
    "        ## forget Gate\n",
    "        f_t=self.sigmoid(self.forget_gate_x(x)+self.forget_gate_h(hn)) # [1,1,100]\n",
    "#         print(f_t.size())\n",
    "        # f_t size [B,hidden_dim]\n",
    "        \n",
    "#         ## 질문 forget gate에서 같은 layer을 의미하는가? ㅇㅇ 공유함. 식이 같음.\n",
    "#         hidden_1= self.forget_gate_input(input) + self.forget_gate_h(hn)\n",
    "#         hidden_1 = self.sigmoid(hidden_1)\n",
    "        \n",
    "        ## input gate\n",
    "        i_t=self.sigmoid(self.input_gate_i_x(x)+self.input_gate_i_h(hn))      #[1,1,100]  \n",
    "        tillde_C = self.tanh(self.input_gate_C_x(x)+self.input_gate_C_h(hn)) # [1,1,100]\n",
    "        \n",
    "        ## cn 업데이트\n",
    "        cn = cn*f_t+i_t*tillde_C # [1,1,100]\n",
    "#         print(cn.size())\n",
    "        \n",
    "        ## output gate\n",
    "        o_t = self.sigmoid(self.output_gate_x(x)+self.output_gate_h(hn))\n",
    "        h_t = o_t * self.tanh(cn)\n",
    "        \n",
    "        # hn 업데이트\n",
    "        hn = h_t # [1,1,100]\n",
    "        \n",
    "        ## 질문 output은 h_t와 같나? 다르다. 여기서 output은 decoder 해줘야함.\n",
    "        output = self.decoder(h_t.view(1,-1)) # [1,100]\n",
    "        \n",
    "        return output, hn, cn\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # The size of h0, c0 should be (layer_dim, batch_size, hidden_dim)\n",
    "        #############\n",
    "        # CODE HERE #\n",
    "        #############\n",
    "        h0 = Variable(torch.zeros(self.layer_dim, 1, self.hidden_dim).cuda()) # initial hidden state [1,1,100]\n",
    "        c0 = Variable(torch.zeros(self.layer_dim, 1, self.hidden_dim).cuda()) # initial cell state [1,1,100]\n",
    "        \n",
    "        return h0, c0\n",
    "    \n",
    "hidden_dim = 100\n",
    "n_layers = 1\n",
    "n_characters = len(all_characters)\n",
    "\n",
    "model = LSTMModel(n_characters, hidden_dim, n_layers, n_characters)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2qajoki2HNF_"
   },
   "source": [
    "### 3. Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-10T13:49:37.104574Z",
     "iopub.status.busy": "2022-03-10T13:49:37.104306Z",
     "iopub.status.idle": "2022-03-10T13:49:37.108309Z",
     "shell.execute_reply": "2022-03-10T13:49:37.107704Z",
     "shell.execute_reply.started": "2022-03-10T13:49:37.104556Z"
    },
    "id": "xvm-picHHNF_"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "lr = 0.005\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5haXxzwOHNF_"
   },
   "source": [
    "### 4 . Write the character level generation code [4 points]\n",
    "\n",
    "- Generate a sentence with a length of $predict\\_len$, starting from a single character $prime\\_str$.\n",
    "- Example) evaluate(prime_str='Y', predict_len=20) -> You better let it go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(prime_str='W', predict_len=20):\n",
    "    inp = char_tensor(prime_str)\n",
    "    # print(inp) # tensor([58])\n",
    "    hidden, cell = model.init_hidden() # 이미 cuda() 올라가 있음.\n",
    "    x = inp.cuda()\n",
    "#     model.cpu()\n",
    "\n",
    "#     print(' W : {}'.format(prime_input))\n",
    "    print(prime_str,end=\"\")\n",
    "    \n",
    "    for p in range(predict_len):\n",
    "        output,hidden, cell= model(x,hidden, cell)\n",
    "        #print(output.data.view(-1)) # torch.Size([100])\n",
    "        #print(output.data.view(-1).div(0.8))\n",
    "        #print(output.data.view(-1).div(0.8).exp())\n",
    "        output_dist = output.data.view(-1).div(0.8).exp()\n",
    "        # output.data.view(-1).div(0.8) output 값을 0.8로 나누는 것이다.\n",
    "        # 그 후 exp()를 씌한다.\n",
    "        # 즉 out_dist에서 얻어진 값이 확률로 해석될 수 있는 텐서가 된다.\n",
    "        # multinomial의 첫번쨰 인자는 확률로 해석될 수 있는 텐서가 들어가고\n",
    "        # 두번째 인자는 샘플링할 갯수가 들어간다.\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        predicted_char = all_characters[top_i]\n",
    "        \n",
    "        print(predicted_char,end=\"\")\n",
    "        \n",
    "        x = char_tensor(predicted_char).cuda()\n",
    "        # x를 계속해서 쓰기 때문에 x를 업데이트 해주면 된다. output으로 원래는 predicted 였지만 의미 없으므로\n",
    "        # return 값이 없어도 된다. 그러나 여기서는 보내야 된다면 그냥 predicted_char 를 보면 될 것 같다.\n",
    "        # 근데 출력이 안 예쁘므로 그냥 생략하자.\n",
    "    #predicted = predicted_char\n",
    "    #return predicted\n",
    "    # -> 이걸 print에서 쓸 것이기 때문에 이렇게하면 none 이 출력된다. 그러므로 문자열을 만들어 주자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(prime_str='W', predict_len=20):\n",
    "    inp = char_tensor(prime_str)\n",
    "    hidden, cell = model.init_hidden() # 이미 cuda() 올라가 있음.\n",
    "    x = inp.cuda()\n",
    "    predicted = str()\n",
    "    predicted = predicted + prime_str\n",
    "    \n",
    "    for p in range(predict_len):\n",
    "        output,hidden, cell= model(x,hidden, cell)\n",
    "        #print(output.data.view(-1)) # torch.Size([100])\n",
    "        #print(output.data.view(-1).div(0.8))\n",
    "        #print(output.data.view(-1).div(0.8).exp())\n",
    "        output_dist = output.data.view(-1).div(0.8).exp()\n",
    "        # output.data.view(-1).div(0.8) output 값을 0.8로 나누는 것이다.\n",
    "        # 그 후 exp()를 씌한다.\n",
    "        # 즉 out_dist에서 얻어진 값이 확률로 해석될 수 있는 텐서가 된다.\n",
    "        # multinomial의 첫번쨰 인자는 확률로 해석될 수 있는 텐서가 들어가고\n",
    "        # 두번째 인자는 샘플링할 갯수가 들어간다.\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        predicted_char = all_characters[top_i]\n",
    "        \n",
    "        predicted = predicted + predicted_char\n",
    "        \n",
    "        x = char_tensor(predicted_char).cuda()\n",
    "        # x를 계속해서 쓰기 때문에 x를 업데이트 해주면 된다. output으로 원래는 predicted 였지만 의미 없으므로\n",
    "        # return 값이 없어도 된다. 그러나 여기서는 보내야 된다면 그냥 predicted_char 를 보면 될 것 같다.\n",
    "        # 근데 출력이 안 예쁘므로 그냥 생략하자.\n",
    "    #predicted = predicted_char\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WT?\u000b",
      "c\n",
      "8*':c=\u000b",
      "F5)QLhf6\n"
     ]
    }
   ],
   "source": [
    "print(evaluate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])\n",
      "tensor([3])\n",
      "tensor([2])\n",
      "tensor([1])\n",
      "tensor([3])\n",
      "tensor([4])\n",
      "tensor([2])\n",
      "tensor([3])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([3])\n",
      "tensor([1])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.tensor([0, 40, 5, 10, 3, 0], dtype=torch.float) # create a tensor of weights\n",
    "print(torch.multinomial(weights, 1))\n",
    "print(torch.multinomial(weights, 1))\n",
    "print(torch.multinomial(weights, 1))\n",
    "print(torch.multinomial(weights, 1))\n",
    "print(torch.multinomial(weights, 1))\n",
    "print(torch.multinomial(weights, 1))\n",
    "print(torch.multinomial(weights, 1))\n",
    "print(torch.multinomial(weights, 1))\n",
    "print(torch.multinomial(weights, 1))\n",
    "print(torch.multinomial(weights, 1))\n",
    "print(torch.multinomial(weights, 1))\n",
    "print(torch.multinomial(weights, 1))\n",
    "# 확률적으로 추출하게 됨. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vt4VFJd5HNF_"
   },
   "source": [
    "### 5 . Write the code to train the model [2 points]\n",
    "\n",
    "- Plot the training loss curve.\n",
    "- Print the output sentence with a length of 100, using $evaluate()$ function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0292,  0.0758,  0.1664, -0.1592,  1.1450],\n",
      "        [-0.2130,  1.1669, -0.5697,  0.7416,  1.6917],\n",
      "        [-2.0640,  0.9690, -0.5804, -0.4183, -0.1007]], requires_grad=True)\n",
      "tensor([[0.0221, 0.2437, 0.2246, 0.4075, 0.1021],\n",
      "        [0.0814, 0.0364, 0.3158, 0.4135, 0.1529],\n",
      "        [0.0263, 0.0243, 0.0490, 0.8479, 0.0525]])\n",
      "tensor([3, 0, 2])\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "print(input)\n",
    "target = torch.randn(3, 5).softmax(dim=1)\n",
    "print(target)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************* epoch100 *************************\n",
      "loss 286.2765\n",
      "Is better is onay molity woreve hall wonis to mut ne tis whanly knorlld mife moss get lor therer cohe \n",
      "\n",
      "************************* epoch200 *************************\n",
      "loss 326.7842\n",
      "IMBat fot her blows thater and\n",
      "An't on anly litt\n",
      "Or momely coke a dot, Note lity doment ever walk a b \n",
      "\n",
      "************************* epoch300 *************************\n",
      "loss 357.5076\n",
      "Ighis opine do no I sombflive the won't pain' and ppime you but better un in a is on in ied ast do fa \n",
      "\n",
      "************************* epoch400 *************************\n",
      "loss 282.1879\n",
      "I nore not ma ling cinge, the mes only mo not ma fargtter jagn li to ceass grome to plo stermbe raily \n",
      "\n",
      "************************* epoch500 *************************\n",
      "loss 265.4240\n",
      "I only faybu beter one shot, but I't spot, don't and to not miss youred and rage\n",
      "Ted is you better\n",
      "Th \n",
      "\n",
      "************************* epoch600 *************************\n",
      "loss 224.0096\n",
      "I't wore tardod\n",
      "He colily tho nerwage\n",
      "Teart, the to don't roab and on to this vomit, yourself in a li \n",
      "\n",
      "************************* epoch700 *************************\n",
      "loss 215.6430\n",
      "I dupside andy forlm all lim one sweade plit\n",
      "You own it, you better jam or chance to blow\n",
      "This opport \n",
      "\n",
      "************************* epoch800 *************************\n",
      "loss 156.4899\n",
      "Iver\n",
      "And uno the supsight beaty\n",
      "He's staping, the movity\n",
      "The opever chaked, but time your chance to b \n",
      "\n",
      "************************* epoch900 *************************\n",
      "loss 24.8786\n",
      "I caught up but I can't paybe, thed\n",
      "In yo, he's bromes yout not\n",
      "So do rhangot\n",
      "To is\n",
      "More doses weak,  \n",
      "\n",
      "************************* epoch1000 *************************\n",
      "loss 141.0136\n",
      "I want to po fIt don't gett go caught home, he's gravity\n",
      "Oh, there cand won't papsin' the pied pwro d \n",
      "\n",
      "************************* epoch1100 *************************\n",
      "loss 96.5146\n",
      "I flow\n",
      "This opho do not miss yourself in the must let it go\n",
      "You own as thera\n",
      "It I mose is mouth, but  \n",
      "\n",
      "************************* epoch1200 *************************\n",
      "loss 78.6429\n",
      "I new world one shot, do not miss your chance to blow\n",
      "This opportunity comes once in a lifetime you b \n",
      "\n",
      "************************* epoch1300 *************************\n",
      "loss 113.3650\n",
      "I upsic, the moment\n",
      "You own it, you better nes\n",
      "in the call and water my seas, show, everybody's jokin \n",
      "\n",
      "************************* epoch1400 *************************\n",
      "loss 57.6291\n",
      "It goes buy misic, the move you, seads, the words won't donc, that his mouth, but the next cipher\n",
      "Bes \n",
      "\n",
      "************************* epoch1500 *************************\n",
      "loss 49.0488\n",
      "I waapturey\n",
      "in yo, he's dope, he knows his whole he whole back city's grows have the suptitugr\n",
      "Back t \n",
      "\n",
      "************************* epoch1600 *************************\n",
      "loss 34.5482\n",
      "It go en, but he's got to go, I cance to blow\n",
      "This opportunity comes once in a lifetime you better\n",
      "Yo \n",
      "\n",
      "************************* epoch1700 *************************\n",
      "loss 41.5261\n",
      "I belo is\n",
      "Se may harder, only knows, he's known as the goes his moment a life is your chance to blow\n",
      " \n",
      "\n",
      "************************* epoch1800 *************************\n",
      "loss 35.0118\n",
      "I cann when it, you better never let it go\n",
      "You only get one shot, do dand bood as and sprlity\n",
      "Oh, the \n",
      "\n",
      "************************* epoch1900 *************************\n",
      "loss 28.4753\n",
      "It\n",
      "You own it, you better never let it go\n",
      "You only get one shot, do not miss your change what he pipe \n",
      "\n",
      "************************* epoch2000 *************************\n",
      "loss 17.3690\n",
      "I miss my life and these times up, over, blaow!\n",
      "Snap back to the next cipher\n",
      "Best believe somebody's  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 2000\n",
    "print_every = 100\n",
    "plot_every = 10\n",
    "\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    # Load text\n",
    "    inputs, targets = random_training_set()\n",
    "    if inputs.size()[0] < 200: continue\n",
    "    \n",
    "#     print(inputs)\n",
    "#     print(targets)\n",
    "    \n",
    "    # 다 gpu로 올리고 최기화 해주자.  # Clear gradients w.r.t. parameters    \n",
    "    hidden , cell = model.init_hidden()\n",
    "    inputs = inputs.cuda()\n",
    "    targets = targets.cuda()\n",
    "    model.zero_grad()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    loss = torch.tensor([0]).type(torch.FloatTensor) # 0으로 해도됨.\n",
    "    for j in range(chunk_len-1):\n",
    "        x  = inputs[j]\n",
    "#         print(x)\n",
    "        y_ = targets[j].unsqueeze(0).type(torch.LongTensor)\n",
    "        y,hidden, cell = model(x,hidden,cell)\n",
    "#         print(y.size())\n",
    "#         print(y_.size())\n",
    "        y= y.cpu()\n",
    "        loss += criterion(y,y_)\n",
    "#         print(loss)\n",
    "\n",
    "        \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # Updating parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    loss_avg += loss.item() / chunk_len\n",
    "    \n",
    "    if epoch % print_every == 0:\n",
    "        print('*'*25, 'epoch%d'%epoch, '*'*25)\n",
    "        print('loss %.4f'%loss.item())\n",
    "        print(evaluate('I', 100), '\\n')\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        loss_avg = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f81ee60e760>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 0~2000epoch\n",
    "#################################################\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XCGRgEuZHNF_"
   },
   "source": [
    "### *References*\n",
    "[1] [practical pytorch](https://github.com/spro/practical-pytorch)(https://github.com/spro/practical-pytorch)\n",
    "\n",
    "[2] [CS 231n](http://cs231n.stanford.edu/syllabus.html)(http://cs231n.stanford.edu/syllabus.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 실험은 NLP의 기본이 되는 모델인 RNN과 LSTM을 분석하는 것이다. RNN은 과거의 정보를 바탕으로 현재를 추정하는 sequence task에 잘 잘동한다. 하지만 long-term 일 경우에는 이론상으로는 가능하지만 gradient vanshing 문제 등이 겹치면서 실제적으로는 잘 작동하지 않는다. 이를 보안하기 위해 만들어진 모델이 LSTM이다. LSTM은 gate를 이용해서 과거의 정보를 얼마나 상쇄시킬것이고 현재의 정보을 얼마나 추가해줄 것인지를 결정하기 때문에 매우 유용하다. 자세한 설명은 예비보고서에서 했으니 생략하겠지만 핵심은 LSTM을 사용했을 때 위의 가사와 같은 문제와 같은 sequence 문제같은 NLP 관련 task를 해결할 수 있다는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예상했던 점 : RNN과 LSTM 모두 반복적인 구조를 이용해서 recurrent하게 학습이 진행되어 sequence task를 수행할 수 있다.\n",
    "    이를 확인하기 위해서 먼저 MNIST dataset을 가지고 분석하였다. MNIST dataset의 28x28을 한 줄씩 sequence로 보아서 \n",
    "    RNN과 LSTM모두 넣어준 결과 각 image가 무엇을 뜻하는 것인지 94~95% 육박하는 성능을 보였다. 따라서 RNN 구조는 매우\n",
    "    효과적인 구조라고 볼 수 있다.\n",
    "    \n",
    "예상과 달랐던 점 및 개선할 점 : \n",
    "input이 element가 1개인 tensor인데 학습이 이루어지는 것이 처음는 너무 이해가 가지 않았다. 그래서 질문도 했지만 뭐가 이해않되고 있는지도 모르고 개념이 전체가 잘못 잡혀있어서 아쉬웠다. 그렇게 검색을 하던 중에 RNN으로 관련 task를 진행한 사이트를 찾을 수 있었고 그 사이트에서 embedding table을 이해할 수 있었다. (위에 링크가 주석으로 되어 있다.)\n",
    "\n",
    " 위의 결과를 보면 알 수 있듯이 Loss 값은 계속 주는 것으로보아 학습이 이루어 지고 있다는 것을 알 수 있다. 출력되는 문자열 역시 가사를 잘 모르지만 이해할 수 있는 알파벳 순서로 나열되어 그럴듯한 결과를 얻을 수 있었다. 여기서 파악할 수 있는 것은 \n",
    "노래 가사라는 짧은 글에 task를 학습하기 위해서 2000 epoch 정도가 필요했다. 사실상 이건 overfitting된 값이기 때문에 가사에 매우 잘 fit한 것으로 볼 수 있지만 (사실상 복사에 가까운 개념이 아닐까?) 실제로는 단어와 문장이 매우 다양하기 때문에 좀 더 명확한 분석이 필요할 것이다. 이를 위해서는 더 큰 data set으로 예상해봐야 할 것 같다.\n",
    "\n",
    "결론 : LSTM과 RNN을 살펴봄을써 NLP 모델의 기초를 학습할 수 있었다. 그리고 embedding table를 이용해서 한 단어를 embedding하여 학습이 가능하다는 것을 깨달을 수 있었다. \n",
    "    \n",
    "의문점 : 블로그에서 소개하길 LSTM의 다음 step이 attention이라고 했는데 이는 어떤 것을 추가해서 성능을 업그레이드 했는지 궁금하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://wjddyd66.github.io/pytorch/Pytorch-RNN&LSTM/ 를 주로 참고하였음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "EEE4423_lab10_Character Generation using LSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torch1.9.0-py3.8-cuda11.1",
   "language": "python",
   "name": "torch1.9.0-py3.8-cuda11.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
